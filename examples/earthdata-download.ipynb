{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Download and virtualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import earthaccess\n",
    "import rasterio\n",
    "import rioxarray  # noqa\n",
    "import s3fs\n",
    "import xarray as xr\n",
    "import zarr\n",
    "from common import earthaccess_args\n",
    "from icechunk import (\n",
    "    IcechunkStore,\n",
    "    S3Credentials,\n",
    "    StorageConfig,\n",
    "    StoreConfig,\n",
    "    VirtualRefConfig,\n",
    ")\n",
    "from rio_cogeo.cogeo import cog_translate\n",
    "from rio_cogeo.profiles import cog_profiles\n",
    "from virtualizarr import open_virtual_dataset\n",
    "from virtualizarr.writers.icechunk import dataset_to_icechunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Setup earthaccess query parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "dataset = \"mursst\"\n",
    "dataset_args = earthaccess_args[dataset]\n",
    "concept_id = dataset_args[\"concept_id\"]\n",
    "filename = dataset_args[\"filename\"]\n",
    "variable = dataset_args[\"variable\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Authenticate via earthaccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "earthaccess.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = earthaccess.search_data(\n",
    "    concept_id=concept_id, count=1, temporal=(\"2002-06-01\", \"2002-06-01\")\n",
    ")\n",
    "fp = earthaccess.download(results, \"earthaccess_data\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Virtualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def virtualize_dataset(local_fp):\n",
    "    \"\"\"Create a virtual reference file for a dataset\"\"\"\n",
    "\n",
    "    def local_to_s3_url(old_local_path: str) -> str:\n",
    "        \"\"\"Replace local path to s3 uri for all chucks\"\"\"\n",
    "\n",
    "        new_s3_bucket_url = Path(\"/\".join(s3_uri.split(\"/\")[1:-1]))\n",
    "        filename = Path(old_local_path).name\n",
    "        new_path = f\"s3:/{str(new_s3_bucket_url / filename)}\"\n",
    "        return new_path\n",
    "\n",
    "    s3_uri = results[0].data_links(access=\"direct\")[0]\n",
    "    virtual_ds = open_virtual_dataset(str(local_fp), indexes={})\n",
    "    virtual_ds = virtual_ds.virtualize.rename_paths(local_to_s3_url)\n",
    "    virtual_ds = virtual_ds[[variable]]\n",
    "    return virtual_ds.drop_vars(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual_ds = virtualize_dataset(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Store virtual dataset as kerchunk reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_uri = results[0].data_links(access=\"direct\")[0]\n",
    "if dataset == \"gpm_merg\":\n",
    "    output_fp = f\"earthaccess_data/{s3_uri.split('/')[-1][:-4]}.json\"\n",
    "else:\n",
    "    output_fp = f\"earthaccess_data/{s3_uri.split('/')[-1][:-3]}.json\"\n",
    "virtual_ds.virtualize.to_kerchunk(output_fp, format=\"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Store virtual dataset using icechunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_creds = earthaccess.get_s3_credentials(daac=dataset_args[\"daac\"])\n",
    "credentials = S3Credentials(\n",
    "    access_key_id=s3_creds[\"accessKeyId\"],\n",
    "    secret_access_key=s3_creds[\"secretAccessKey\"],\n",
    "    session_token=s3_creds[\"sessionToken\"],\n",
    ")\n",
    "storage = StorageConfig.s3_from_env(\n",
    "    bucket=\"nasa-veda-scratch\",\n",
    "    prefix=f\"resampling/icechunk/{dataset}-reference\",\n",
    "    region=\"us-west-2\",\n",
    ")\n",
    "config = StoreConfig(\n",
    "    virtual_ref_config=VirtualRefConfig.s3_from_config(credentials=credentials),\n",
    ")\n",
    "virtual_store = IcechunkStore.open_or_create(storage=storage, config=config, mode=\"w\")\n",
    "dataset_to_icechunk(virtual_ds, virtual_store)\n",
    "virtual_store.commit(\"Create refenence dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Store dataset using Zarr V3 and icechunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual_storage = StorageConfig.s3_from_env(\n",
    "    bucket=\"nasa-veda-scratch\",\n",
    "    prefix=f\"resampling/icechunk/{dataset}-reference\",\n",
    "    region=\"us-west-2\",\n",
    ")\n",
    "virtual_store = IcechunkStore.open_existing(storage=virtual_storage, mode=\"r\")\n",
    "ds = xr.open_zarr(virtual_store, zarr_format=3, consolidated=False).load()\n",
    "ds = ds.drop_encoding()\n",
    "ds = ds.squeeze()\n",
    "if dataset == \"gpm_imerg\":\n",
    "    ds = ds.transpose(\"lat\", \"lon\")\n",
    "encoding = {\n",
    "    variable: {\n",
    "        \"codecs\": [zarr.codecs.BytesCodec(), zarr.codecs.ZstdCodec()],\n",
    "    }\n",
    "}\n",
    "storage = StorageConfig.s3_from_env(\n",
    "    bucket=\"nasa-veda-scratch\",\n",
    "    prefix=f\"resampling/icechunk/{dataset}\",\n",
    "    region=\"us-west-2\",\n",
    ")\n",
    "store = IcechunkStore.open_or_create(storage=storage, mode=\"w\")\n",
    "ds.to_zarr(store, zarr_format=3, consolidated=False, encoding=encoding)\n",
    "store.commit(\"Add dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Store dataset as COG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _translate(src_path, dst_path, profile=\"zstd\", profile_options={}, **options):\n",
    "    \"\"\"\n",
    "    Convert image to COG.\n",
    "\n",
    "    From https://cogeotiff.github.io/rio-cogeo/API/\n",
    "    \"\"\"\n",
    "    # Format creation option (see gdalwarp `-co` option)\n",
    "    output_profile = cog_profiles.get(profile)\n",
    "    output_profile.update(dict(BIGTIFF=\"IF_SAFER\"))\n",
    "    output_profile.update(profile_options)\n",
    "\n",
    "    # Dataset Open option (see gdalwarp `-oo` option)\n",
    "    config = dict(\n",
    "        GDAL_NUM_THREADS=\"ALL_CPUS\",\n",
    "        GDAL_TIFF_INTERNAL_MASK=True,\n",
    "        GDAL_TIFF_OVR_BLOCKSIZE=\"128\",\n",
    "    )\n",
    "\n",
    "    cog_translate(\n",
    "        src_path,\n",
    "        dst_path,\n",
    "        output_profile,\n",
    "        config=config,\n",
    "        in_memory=False,\n",
    "        quiet=True,\n",
    "        **options,\n",
    "    )\n",
    "    return True\n",
    "\n",
    "\n",
    "# Only store MUR SST since it has the expected (time, y, x) axis order\n",
    "if dataset == \"mursst\":\n",
    "    args = earthaccess_args[dataset]\n",
    "    src = f'NETCDF:earthaccess_data/{args[\"filename\"]}:{args[\"variable\"]}'\n",
    "    dst = f\"earthaccess_data/{dataset}.tif\"\n",
    "    # Generate local COG\n",
    "    with rasterio.open(src) as da:\n",
    "        _translate(da, dst)\n",
    "    # Upload to S3\n",
    "    remote_uri = f\"s3://nasa-veda-scratch/resampling/{dataset}.tif\"\n",
    "    fs = s3fs.S3FileSystem()\n",
    "    fs.put(dst, remote_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Store overviews as Zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "local = False\n",
    "if local:\n",
    "    dst = f\"{os.getcwd()}/earthaccess_data/{dataset}-overviews.zarr\"\n",
    "    storage = StorageConfig.filesystem(dst)\n",
    "\n",
    "else:\n",
    "    storage = StorageConfig.s3_from_env(\n",
    "        bucket=\"nasa-veda-scratch\",\n",
    "        prefix=f\"resampling/icechunk/{dataset}-overviews.zarr\",\n",
    "        region=\"us-west-2\",\n",
    "    )\n",
    "store = IcechunkStore.open_or_create(storage=storage, mode=\"w\")\n",
    "src = f\"earthaccess_data/{dataset}.tif\"\n",
    "cog = rasterio.open(src)\n",
    "data = rioxarray.open_rasterio(src)\n",
    "scale = float(data.attrs[\"scale_factor\"])\n",
    "offset = float(data.attrs[\"add_offset\"])\n",
    "data = rioxarray.open_rasterio(src)\n",
    "data = data.drop_encoding()\n",
    "data.attrs = {}\n",
    "encoding = {\"var\": {\"codecs\": [zarr.codecs.BytesCodec(), zarr.codecs.ZstdCodec()]}}\n",
    "\n",
    "data = data.to_dataset(name=\"var\")\n",
    "data.to_zarr(store, group=\"data\", mode=\"w\", encoding=encoding)\n",
    "for ind, level in enumerate(cog.overviews(1)):\n",
    "    overview = rioxarray.open_rasterio(src, overview_level=ind)\n",
    "    overview = overview.load() * scale + offset\n",
    "    overview = overview.drop_encoding()\n",
    "    overview.attrs = {}\n",
    "    overview = overview.to_dataset(name=\"var\")\n",
    "    overview.to_zarr(store, group=str(level), mode=\"w\", encoding=encoding)\n",
    "store.commit(\"Add overviews\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
