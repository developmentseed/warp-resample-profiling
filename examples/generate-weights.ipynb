{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pyproj\n",
    "import rasterio.transform\n",
    "import sparse\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "from common import earthaccess_args, target_extent\n",
    "from icechunk import IcechunkStore, StorageConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid_ds(*, te, tilesize, dstSRS) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Make a dataset representing a target grid\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xr.Dataset\n",
    "        Target grid dataset with the following variables:\n",
    "        - \"x\": X coordinate in Web Mercator projection (grid cell center)\n",
    "        - \"y\": Y coordinate in Web Mercator projection (grid cell center)\n",
    "        - \"lat\": latitude coordinate (grid cell center)\n",
    "        - \"lon\": longitude coordinate (grid cell center)\n",
    "        - \"lat_b\": latitude bounds for grid cell\n",
    "        - \"lon_b\": longitude bounds for grid cell\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Modified from ndpyramid - https://github.com/carbonplan/ndpyramid\n",
    "    \"\"\"\n",
    "\n",
    "    transform = rasterio.transform.Affine.translation(\n",
    "        te[0], te[3]\n",
    "    ) * rasterio.transform.Affine.scale((te[2] * 2) / tilesize, (te[1] * 2) / tilesize)\n",
    "\n",
    "    p = pyproj.Proj(dstSRS)\n",
    "\n",
    "    grid_shape = (tilesize, tilesize)\n",
    "    bounds_shape = (tilesize + 1, tilesize + 1)\n",
    "\n",
    "    xs = np.empty(grid_shape)\n",
    "    ys = np.empty(grid_shape)\n",
    "    lat = np.empty(grid_shape)\n",
    "    lon = np.empty(grid_shape)\n",
    "    lat_b = np.zeros(bounds_shape)\n",
    "    lon_b = np.zeros(bounds_shape)\n",
    "\n",
    "    # calc grid cell center coordinates\n",
    "    ii, jj = np.meshgrid(np.arange(tilesize) + 0.5, np.arange(tilesize) + 0.5)\n",
    "    for i, j in itertools.product(range(grid_shape[0]), range(grid_shape[1])):\n",
    "        locs = [ii[i, j], jj[i, j]]\n",
    "        xs[i, j], ys[i, j] = transform * locs\n",
    "        lon[i, j], lat[i, j] = p(xs[i, j], ys[i, j], inverse=True)\n",
    "\n",
    "    # calc grid cell bounds\n",
    "    iib, jjb = np.meshgrid(np.arange(tilesize + 1), np.arange(tilesize + 1))\n",
    "    for i, j in itertools.product(range(bounds_shape[0]), range(bounds_shape[1])):\n",
    "        locs = [iib[i, j], jjb[i, j]]\n",
    "        x, y = transform * locs\n",
    "        lon_b[i, j], lat_b[i, j] = p(x, y, inverse=True)\n",
    "\n",
    "    latitude = xr.DataArray(\n",
    "        lat[:, 0],\n",
    "        dims=\"y\",\n",
    "        attrs=dict(\n",
    "            standard_name=\"latitude\",\n",
    "            long_name=\"Latitude\",\n",
    "            units=\"degrees_north\",\n",
    "            axis=\"X\",\n",
    "        ),\n",
    "    )\n",
    "    longitude = xr.DataArray(\n",
    "        lon[0, :],\n",
    "        dims=\"x\",\n",
    "        attrs=dict(\n",
    "            standard_name=\"longitude\",\n",
    "            long_name=\"Longitude\",\n",
    "            units=\"degrees_east\",\n",
    "            axis=\"Y\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return xr.Dataset(\n",
    "        {\n",
    "            \"lat_b\": xr.DataArray(lat_b, dims=[\"y_b\", \"x_b\"]),\n",
    "            \"lon_b\": xr.DataArray(lon_b, dims=[\"y_b\", \"x_b\"]),\n",
    "        },\n",
    "        {\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude,\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "def xesmf_weights_to_xarray(regridder) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Construct an xarray dataset from XESMF weights\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    From ndpyramid - https://github.com/carbonplan/ndpyramid\n",
    "    \"\"\"\n",
    "    w = regridder.weights.data\n",
    "    dim = \"n_s\"\n",
    "    ds = xr.Dataset(\n",
    "        {\n",
    "            \"S\": (dim, w.data),\n",
    "            \"col\": (dim, w.coords[1, :] + 1),\n",
    "            \"row\": (dim, w.coords[0, :] + 1),\n",
    "        }\n",
    "    )\n",
    "    ds.attrs = {\"n_in\": regridder.n_in, \"n_out\": regridder.n_out}\n",
    "    return ds\n",
    "\n",
    "\n",
    "def _reconstruct_xesmf_weights(ds_w):\n",
    "    \"\"\"\n",
    "    Reconstruct weights into format that xESMF understands\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    From ndpyramid - https://github.com/carbonplan/ndpyramid\n",
    "    \"\"\"\n",
    "\n",
    "    col = ds_w[\"col\"].values - 1\n",
    "    row = ds_w[\"row\"].values - 1\n",
    "    s = ds_w[\"S\"].values\n",
    "    n_out, n_in = ds_w.attrs[\"n_out\"], ds_w.attrs[\"n_in\"]\n",
    "    crds = np.stack([row, col])\n",
    "    return xr.DataArray(\n",
    "        sparse.COO(crds, s, (n_out, n_in)), dims=(\"out_dim\", \"in_dim\"), name=\"weights\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weights(dataset, zoom):\n",
    "    te = target_extent[zoom]\n",
    "\n",
    "    # Define filepath, driver, and variable information\n",
    "    args = earthaccess_args[dataset]\n",
    "    # Create icechunk repos for caching weights and target grid\n",
    "    weights_storage = StorageConfig.s3_from_env(\n",
    "        bucket=\"nasa-veda-scratch\",\n",
    "        prefix=f\"resampling/test-weight-caching/{dataset}-weights-{zoom}\",\n",
    "        region=\"us-west-2\",\n",
    "    )\n",
    "    target_storage = StorageConfig.s3_from_env(\n",
    "        bucket=\"nasa-veda-scratch\",\n",
    "        prefix=f\"resampling/test-weight-caching/{dataset}-target-{zoom}\",\n",
    "        region=\"us-west-2\",\n",
    "    )\n",
    "    weights_store = IcechunkStore.open_or_create(storage=weights_storage, mode=\"w\")\n",
    "    target_store = IcechunkStore.open_or_create(storage=target_storage, mode=\"w\")\n",
    "    # Create target grid\n",
    "    target_grid = make_grid_ds(te=te, tilesize=256, dstSRS=\"EPSG:3857\")\n",
    "    # Open dataset\n",
    "    storage = StorageConfig.s3_from_env(\n",
    "        bucket=\"nasa-veda-scratch\",\n",
    "        prefix=f\"resampling/icechunk/{dataset}\",\n",
    "        region=\"us-west-2\",\n",
    "    )\n",
    "    store = IcechunkStore.open_existing(storage=storage, mode=\"r\")\n",
    "    da = xr.open_zarr(store, zarr_format=3, consolidated=False)[args[\"variable\"]]\n",
    "    # Chunk target grid for parallel weights generations\n",
    "    output_chunk_size = 128\n",
    "    target_grid = target_grid.chunk(\n",
    "        {\n",
    "            \"x\": output_chunk_size,\n",
    "            \"y\": output_chunk_size,\n",
    "            \"y_b\": output_chunk_size,\n",
    "            \"x_b\": output_chunk_size,\n",
    "        }\n",
    "    )\n",
    "    # Create XESMF regridder\n",
    "    regridder = xe.Regridder(\n",
    "        da,\n",
    "        target_grid,\n",
    "        \"nearest_s2d\",\n",
    "        periodic=True,\n",
    "        extrap_method=\"nearest_s2d\",\n",
    "        ignore_degenerate=True,\n",
    "        parallel=True,\n",
    "    )\n",
    "    # Convert weigts to a dataset\n",
    "    weights = xesmf_weights_to_xarray(regridder)\n",
    "    # Store weights using icechunk\n",
    "    weights.to_zarr(weights_store, zarr_format=3, consolidated=False)\n",
    "    # Commit data to icechunk stores\n",
    "    weights_store.commit(\"Store weights\")\n",
    "    # Store target grid using icechunk\n",
    "    target_grid.load().to_zarr(target_store, zarr_format=3, consolidated=False)\n",
    "    target_store.commit(\"Generate target grid\")\n",
    "    # Store weights using Zarr\n",
    "    output = f\"s3://nasa-veda-scratch/resampling/test-weight-caching/{dataset}-weights-{zoom}.zarr\"\n",
    "    weights.to_zarr(output, mode=\"w\", storage_options={\"use_listings_cache\": False})\n",
    "    # Store target grid using Zarr\n",
    "    output = f\"s3://nasa-veda-scratch/resampling/test-weight-caching/{dataset}-target-{zoom}.zarr\"\n",
    "    target_grid.to_zarr(output, mode=\"w\", storage_options={\"use_listings_cache\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"gpm_imerg\"\n",
    "generate_weights(dataset, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_weights(dataset, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_weights(dataset, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
