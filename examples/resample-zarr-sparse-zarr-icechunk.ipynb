{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling with sparse (S3 storage, Zarr V3 store, Zarr reader with icechunk)Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from common import earthaccess_args\n",
    "from icechunk import IcechunkStore, StorageConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reconstruct_xesmf_weights(ds_w):\n",
    "    \"\"\"\n",
    "    Reconstruct weights into format that xESMF understands\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    From ndpyramid - https://github.com/carbonplan/ndpyramid\n",
    "    \"\"\"\n",
    "    import sparse\n",
    "    import xarray as xr\n",
    "\n",
    "    col = ds_w[\"col\"].values - 1\n",
    "    row = ds_w[\"row\"].values - 1\n",
    "    s = ds_w[\"S\"].values\n",
    "    n_out, n_in = ds_w.attrs[\"n_out\"], ds_w.attrs[\"n_in\"]\n",
    "    crds = np.stack([row, col])\n",
    "    return xr.DataArray(\n",
    "        sparse.COO(crds, s, (n_out, n_in)), dims=(\"out_dim\", \"in_dim\"), name=\"weights\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xr_regridder(\n",
    "    ds: xr.Dataset,\n",
    "    grid: xr.Dataset,\n",
    "    weights: xr.DataArray,\n",
    ") -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Xarray-aware regridding function that uses weights from xESMF but performs the regridding using sparse matrix multiplication.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds\n",
    "    weights\n",
    "    out_grid_shape\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    regridded_ds\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Modified from https://github.com/carbonplan/ndpyramid/pull/130\n",
    "    \"\"\"\n",
    "\n",
    "    latlon_dims = [\"lat\", \"lon\"]\n",
    "\n",
    "    shape_in = (ds.sizes[\"lat\"], ds.sizes[\"lon\"])\n",
    "    shape_out = (grid.sizes[\"y\"], grid.sizes[\"x\"])\n",
    "\n",
    "    regridded_ds = xr.apply_ufunc(\n",
    "        esmf_apply_weights,\n",
    "        weights,\n",
    "        ds,\n",
    "        input_core_dims=[[\"out_dim\", \"in_dim\"], latlon_dims],\n",
    "        output_core_dims=[latlon_dims],\n",
    "        exclude_dims=set(latlon_dims),\n",
    "        kwargs={\"shape_in\": shape_in, \"shape_out\": shape_out},\n",
    "        keep_attrs=True,\n",
    "    )\n",
    "\n",
    "    return regridded_ds\n",
    "\n",
    "\n",
    "def esmf_apply_weights(weights, indata, shape_in, shape_out):\n",
    "    \"\"\"\n",
    "    Apply regridding weights to data.\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : scipy sparse COO matrix\n",
    "    indata : numpy array of shape ``(..., n_lat, n_lon)`` or ``(..., n_y, n_x)``.\n",
    "        Should be C-ordered. Will be then tranposed to F-ordered.\n",
    "    shape_in, shape_out : tuple of two integers\n",
    "        Input/output data shape for unflatten operation.\n",
    "        For rectilinear grid, it is just ``(n_lat, n_lon)``.\n",
    "    Returns\n",
    "    -------\n",
    "    outdata : numpy array of shape ``(..., shape_out[0], shape_out[1])``.\n",
    "        Extra dimensions are the same as `indata`.\n",
    "        If input data is C-ordered, output will also be C-ordered.\n",
    "    Notes\n",
    "    -----\n",
    "    From https://github.com/carbonplan/ndpyramid/pull/130\n",
    "    \"\"\"\n",
    "\n",
    "    # COO matrix is fast with F-ordered array but slow with C-array, so we\n",
    "    # take in a C-ordered and then transpose)\n",
    "    # (CSR or CRS matrix is fast with C-ordered array but slow with F-array)\n",
    "    if not indata.flags[\"C_CONTIGUOUS\"]:\n",
    "        warnings.warn(\"Input array is not C_CONTIGUOUS. \" \"Will affect performance.\")\n",
    "\n",
    "    # get input shape information\n",
    "    shape_horiz = indata.shape[-2:]\n",
    "    extra_shape = indata.shape[0:-2]\n",
    "\n",
    "    assert shape_horiz == shape_in, (\n",
    "        \"The horizontal shape of input data is {}, different from that of\"\n",
    "        \"the regridder {}!\".format(shape_horiz, shape_in)\n",
    "    )\n",
    "\n",
    "    assert (\n",
    "        shape_in[0] * shape_in[1] == weights.shape[1]\n",
    "    ), \"ny_in * nx_in should equal to weights.shape[1]\"\n",
    "\n",
    "    assert (\n",
    "        shape_out[0] * shape_out[1] == weights.shape[0]\n",
    "    ), \"ny_out * nx_out should equal to weights.shape[0]\"\n",
    "\n",
    "    # use flattened array for dot operation\n",
    "    indata_flat = indata.reshape(-1, shape_in[0] * shape_in[1])\n",
    "    outdata_flat = weights.dot(indata_flat.T).T\n",
    "\n",
    "    # unflattened output array\n",
    "    outdata = outdata_flat.reshape([*extra_shape, shape_out[0], shape_out[1]])\n",
    "    return outdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrid(dataset, zoom=0):\n",
    "\n",
    "    args = earthaccess_args[dataset]\n",
    "    # Load pre-generated weights and target dataset\n",
    "    weights_storage = StorageConfig.s3_from_env(\n",
    "        bucket=\"nasa-veda-scratch\",\n",
    "        prefix=f\"resampling/test-weight-caching/{dataset}-weights-{zoom}\",\n",
    "        region=\"us-west-2\",\n",
    "    )\n",
    "    target_storage = StorageConfig.s3_from_env(\n",
    "        bucket=\"nasa-veda-scratch\",\n",
    "        prefix=f\"resampling/test-weight-caching/{dataset}-target-{zoom}\",\n",
    "        region=\"us-west-2\",\n",
    "    )\n",
    "    weights_store = IcechunkStore.open_existing(storage=weights_storage, mode=\"r\")\n",
    "    target_store = IcechunkStore.open_existing(storage=target_storage, mode=\"r\")\n",
    "    weights = _reconstruct_xesmf_weights(\n",
    "        xr.open_zarr(weights_store, zarr_format=3, consolidated=False)\n",
    "    )\n",
    "    grid = xr.open_zarr(target_store, zarr_format=3, consolidated=False).load()\n",
    "    # Open dataset\n",
    "    storage = StorageConfig.s3_from_env(\n",
    "        bucket=\"nasa-veda-scratch\",\n",
    "        prefix=f\"resampling/icechunk/{dataset}\",\n",
    "        region=\"us-west-2\",\n",
    "    )\n",
    "    store = IcechunkStore.open_existing(storage=storage, mode=\"r\")\n",
    "    da = xr.open_zarr(store, zarr_format=3, consolidated=False)[args[\"variable\"]].load()\n",
    "    return xr_regridder(da, grid, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if \"get_ipython\" in dir():\n",
    "        # Just call warp_resample if running as a Jupyter Notebook\n",
    "        da = regrid(\"gpm_imerg\")\n",
    "    else:\n",
    "        # Configure dataset via argpase if running via CLI\n",
    "        parser = argparse.ArgumentParser(description=\"Set environment for the script.\")\n",
    "        parser.add_argument(\n",
    "            \"--dataset\",\n",
    "            default=\"gpm_imerg\",\n",
    "            help=\"Dataset to resample.\",\n",
    "            choices=[\"gpm_imerg\", \"mursst\"],\n",
    "        )\n",
    "        parser.add_argument(\n",
    "            \"--zoom\",\n",
    "            default=0,\n",
    "            help=\"Zoom level for tile extent.\",\n",
    "        )\n",
    "        user_args = parser.parse_args()\n",
    "        da = regrid(user_args.dataset, int(user_args.zoom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
