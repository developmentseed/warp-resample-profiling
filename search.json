[
  {
    "objectID": "pages/slides.html#a-bit-of-background-about-me-and-this-work",
    "href": "pages/slides.html#a-bit-of-background-about-me-and-this-work",
    "title": "Geospatial reprojection in Python",
    "section": "A bit of background about me and this work",
    "text": "A bit of background about me and this work",
    "crumbs": [
      "Overview Slides"
    ]
  },
  {
    "objectID": "pages/slides.html#caveats",
    "href": "pages/slides.html#caveats",
    "title": "Geospatial reprojection in Python",
    "section": "Caveats",
    "text": "Caveats\n\nWork in progress!\nRecording will quickly become out-of-date\nVerify/fix code before use",
    "crumbs": [
      "Overview Slides"
    ]
  },
  {
    "objectID": "pages/slides.html#definitions",
    "href": "pages/slides.html#definitions",
    "title": "Geospatial reprojection in Python",
    "section": "Definitions",
    "text": "Definitions\nReprojection - changing the projection of a dataset from one coordinate reference system (CRS) to another",
    "crumbs": [
      "Overview Slides"
    ]
  },
  {
    "objectID": "pages/slides.html#definitions-1",
    "href": "pages/slides.html#definitions-1",
    "title": "Geospatial reprojection in Python",
    "section": "Definitions",
    "text": "Definitions\nResampling/regridding - changing the grid structure (often resolution)",
    "crumbs": [
      "Overview Slides"
    ]
  },
  {
    "objectID": "pages/slides.html#definitions-2",
    "href": "pages/slides.html#definitions-2",
    "title": "Geospatial reprojection in Python",
    "section": "Definitions",
    "text": "Definitions\nWarp resampling - changing the resolution and projection of a dataset",
    "crumbs": [
      "Overview Slides"
    ]
  },
  {
    "objectID": "pages/slides.html#grid-structures",
    "href": "pages/slides.html#grid-structures",
    "title": "Geospatial reprojection in Python",
    "section": "Grid structures",
    "text": "Grid structures\n\nRectilinear - described by one-dimensional latitude and longitude coordinates\n\nRegular - described by one x,y coordinate and the resolution\n\nCurvilinear - described by two-dimensional latitude and longitude coordinates\nUnstructured - Grids in which the grid coordinates require a list of nodes\n\n\nReview NCAR’s climate data guide for more information",
    "crumbs": [
      "Overview Slides"
    ]
  },
  {
    "objectID": "pages/slides.html#resampling-algorithms",
    "href": "pages/slides.html#resampling-algorithms",
    "title": "Geospatial reprojection in Python",
    "section": "Resampling algorithms",
    "text": "Resampling algorithms\n\nNearest neighbor\nBilinear\nCubic\nSpline\nInverse distance\nBucket / binning (average, min, max, mode, med, quartile, sum, rms)\nSpectral\nTriangulation\nConservative\n\n\nReview NCAR’s climate data guide for more information",
    "crumbs": [
      "Overview Slides"
    ]
  },
  {
    "objectID": "pages/slides.html#some-of-the-many-reasons-to-warp-resample",
    "href": "pages/slides.html#some-of-the-many-reasons-to-warp-resample",
    "title": "Geospatial reprojection in Python",
    "section": "Some of the many reasons to warp resample",
    "text": "Some of the many reasons to warp resample\nCo-registering datasets\n\nMosaicing\nStatistical analyses\nMachine learning\n\nVisualization\n\nRendering (minimize distortion)\nBuilding overviews",
    "crumbs": [
      "Overview Slides"
    ]
  },
  {
    "objectID": "pages/slides.html#observations-and-opinions",
    "href": "pages/slides.html#observations-and-opinions",
    "title": "Geospatial reprojection in Python",
    "section": "Observations and opinions",
    "text": "Observations and opinions\n\nLots of kernels were killed in the making of this presentation\n\nwe need a demo using a bounded-memory approach (Cubed!)\n\nThere are some awesome data cube libraries in Python\n\nlet’s work with the developers to make them even better…and not build another one\n\nXarray’s data model is intuitive for a lot of people\n\nuse accessors to extend it’s functionality rather than a new data class",
    "crumbs": [
      "Overview Slides"
    ]
  },
  {
    "objectID": "pages/slides.html#whats-next-for-the-guide",
    "href": "pages/slides.html#whats-next-for-the-guide",
    "title": "Geospatial reprojection in Python",
    "section": "What’s next for the guide",
    "text": "What’s next for the guide\n\nTry caching weights\nSmall tile from a large dataset\nAdd information about grid structures supported\nAdd information about resampling methods supported\nTest with virtualized data\nTest with cloud optimized data\nTest with other resampling algorithms",
    "crumbs": [
      "Overview Slides"
    ]
  },
  {
    "objectID": "pages/slides.html#thanks",
    "href": "pages/slides.html#thanks",
    "title": "Geospatial reprojection in Python",
    "section": "Thanks",
    "text": "Thanks\n\nDevelopment Seed\nPangeo Community\n\nspecial thanks to Justus, Michael, and Deepak\n\nNASA IMPACT",
    "crumbs": [
      "Overview Slides"
    ]
  },
  {
    "objectID": "pages/slides.html#whats-next-for-resampling-in-python",
    "href": "pages/slides.html#whats-next-for-resampling-in-python",
    "title": "Geospatial reprojection in Python",
    "section": "What’s next for resampling in Python",
    "text": "What’s next for resampling in Python\nLet’s discuss!",
    "crumbs": [
      "Overview Slides"
    ]
  },
  {
    "objectID": "examples/run-pyinstrument.html",
    "href": "examples/run-pyinstrument.html",
    "title": "Geospatial reprojection in Python (2024)",
    "section": "",
    "text": "import subprocess\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Literal\n\nimport fsspec\nfrom utils import sync_notebook\n\n\nfs = fsspec.filesystem(\"file\")\ncurrent_date = datetime.today().strftime(\"%Y-%m-%d\")\noutput_folder = f\"results/{current_date}/\"\nfiles = fs.glob(f\"{output_folder}pyinstrument-*.json\")\nfs.rm(files)\nfs.mkdirs(output_folder, exist_ok=True)\n\n\ndataset = \"gpm_imerg\"\n\n\ndef run_pyinstrument(file: str, output_format: Literal[\"json\", \"html\"]):\n    output_file = (\n        output_folder\n        + \"pyinstrument-\"\n        + dataset\n        + \"-\"\n        + Path(file).stem\n        + \".\"\n        + output_format\n    )\n    command = [\n        \"pyinstrument\",\n        \"--outfile\",\n        output_file,\n        \"-r\",\n        output_format,\n        file,\n        \"--dataset\",\n        dataset,\n    ]\n    subprocess.run(command)\n\n\ninput_methods = [\"resample-rioxarray-h5netcdf\", \"resample-odc\", \"resample-xesmf\"]\n\n\nnotebooks = []\nfor fp in input_methods:\n    notebooks.extend(fs.glob(f\"{fp}*.ipynb\"))\n\n\nfor file in notebooks:\n    sync_notebook(file)\n\n\nmodules = []\nfor fp in input_methods:\n    modules.extend(fs.glob(f\"{fp}*.py\"))\nfor file in modules:\n    run_pyinstrument(file, \"json\")"
  },
  {
    "objectID": "examples/resample-xesmfcached-zarr-kerchunk.html",
    "href": "examples/resample-xesmfcached-zarr-kerchunk.html",
    "title": "XESMF with Zarr, kerchunk, earthaccess, and pre-generated weights",
    "section": "",
    "text": "Requires the upcoming ESMF 8.7 release for high-resolution datasets - https://github.com/pangeo-data/xESMF/issues/380\n\nimport argparse\nimport itertools\n\nimport earthaccess\nimport fsspec\nimport numpy as np\nimport pyproj\nimport rasterio.transform\nimport xarray as xr\nimport xesmf as xe\nfrom common import earthaccess_args\n\n\ndef make_grid_ds() -&gt; xr.Dataset:\n    \"\"\"\n    Modified from ndpyramid - https://github.com/carbonplan/ndpyramid\n    \"\"\"\n    dstSRS = \"EPSG:3857\"\n    width = height = 256\n    te = [\n        -20037508.342789244,\n        -20037508.342789244,\n        20037508.342789244,\n        20037508.342789244,\n    ]\n\n    transform = rasterio.transform.Affine.translation(\n        te[0], te[3]\n    ) * rasterio.transform.Affine.scale((te[2] * 2) / width, (te[1] * 2) / height)\n\n    p = pyproj.Proj(dstSRS)\n\n    grid_shape = (height, width)\n    bounds_shape = (height + 1, width + 1)\n\n    xs = np.empty(grid_shape)\n    ys = np.empty(grid_shape)\n    lat = np.empty(grid_shape)\n    lon = np.empty(grid_shape)\n    lat_b = np.zeros(bounds_shape)\n    lon_b = np.zeros(bounds_shape)\n\n    # calc grid cell center coordinates\n    ii, jj = np.meshgrid(np.arange(height) + 0.5, np.arange(width) + 0.5)\n    for i, j in itertools.product(range(grid_shape[0]), range(grid_shape[1])):\n        locs = [ii[i, j], jj[i, j]]\n        xs[i, j], ys[i, j] = transform * locs\n        lon[i, j], lat[i, j] = p(xs[i, j], ys[i, j], inverse=True)\n\n    # calc grid cell bounds\n    iib, jjb = np.meshgrid(np.arange(height + 1), np.arange(width + 1))\n    for i, j in itertools.product(range(bounds_shape[0]), range(bounds_shape[1])):\n        locs = [iib[i, j], jjb[i, j]]\n        x, y = transform * locs\n        lon_b[i, j], lat_b[i, j] = p(x, y, inverse=True)\n\n    return xr.Dataset(\n        {\n            \"x\": xr.DataArray(xs[0, :], dims=[\"x\"]),\n            \"y\": xr.DataArray(ys[:, 0], dims=[\"y\"]),\n            \"lat\": xr.DataArray(lat, dims=[\"y\", \"x\"]),\n            \"lon\": xr.DataArray(lon, dims=[\"y\", \"x\"]),\n            \"lat_b\": xr.DataArray(lat_b, dims=[\"y_b\", \"x_b\"]),\n            \"lon_b\": xr.DataArray(lon_b, dims=[\"y_b\", \"x_b\"]),\n        },\n    )\n\n\ndef xesmf_weights_to_xarray(regridder) -&gt; xr.Dataset:\n    \"\"\"\n    From ndpyramid - https://github.com/carbonplan/ndpyramid\n    \"\"\"\n    w = regridder.weights.data\n    dim = \"n_s\"\n    ds = xr.Dataset(\n        {\n            \"S\": (dim, w.data),\n            \"col\": (dim, w.coords[1, :] + 1),\n            \"row\": (dim, w.coords[0, :] + 1),\n        }\n    )\n    ds.attrs = {\"n_in\": regridder.n_in, \"n_out\": regridder.n_out}\n    return ds\n\n\ndef _reconstruct_xesmf_weights(ds_w):\n    \"\"\"\n    Reconstruct weights into format that xESMF understands\n\n    From ndpyramid - https://github.com/carbonplan/ndpyramid\n    \"\"\"\n    import sparse\n    import xarray as xr\n\n    col = ds_w[\"col\"].values - 1\n    row = ds_w[\"row\"].values - 1\n    s = ds_w[\"S\"].values\n    n_out, n_in = ds_w.attrs[\"n_out\"], ds_w.attrs[\"n_in\"]\n    crds = np.stack([row, col])\n    return xr.DataArray(\n        sparse.COO(crds, s, (n_out, n_in)), dims=(\"out_dim\", \"in_dim\"), name=\"weights\"\n    )\n\n\ndef reconstruct_weights(weights_fp):\n    return _reconstruct_xesmf_weights(xr.open_zarr(weights_fp))\n\n\ndef get_weights_fp(earthaccess_args):\n    return (\n        \"s3://nasa-veda-scratch/test-weight-caching/\"\n        + earthaccess_args[\"filename\"][:-4]\n        + \"_weights.zarr\"\n    )\n\n\ndef get_target_grid_fp(earthaccess_args):\n    return (\n        \"s3://nasa-veda-scratch/test-weight-caching/\"\n        + earthaccess_args[\"filename\"][:-4]\n        + \"_target.zarr\"\n    )\n\n\ndef generate_weights(dataset):\n    args = earthaccess_args[dataset]\n    weights_fp = get_weights_fp(args)\n    target_grid_fp = get_target_grid_fp(args)\n    input_uri = f'{args[\"folder\"]}/{args[\"filename\"]}'\n    src = f's3://{args[\"bucket\"]}/{input_uri}'\n    target_grid = make_grid_ds()\n    target_grid.to_zarr(target_grid_fp, mode=\"w\")\n    fs = earthaccess.get_s3fs_session(daac=args[\"daac\"])\n    fsspec_caching = {\n        \"cache_type\": \"none\",\n    }\n    with fs.open(src, **fsspec_caching) as f:\n        da = xr.open_dataset(f, engine=\"h5netcdf\", chunks={}, mask_and_scale=True)[\n            args[\"variable\"]\n        ]\n        regridder = xe.Regridder(\n            da,\n            target_grid,\n            \"nearest_s2d\",\n            periodic=True,\n            extrap_method=\"nearest_s2d\",\n            ignore_degenerate=True,\n        )\n        weights = xesmf_weights_to_xarray(regridder)\n        weights.to_zarr(weights_fp, mode=\"w\")\n\n\ndef regrid(dataset):\n    args = earthaccess_args[dataset]\n    weights_fp = get_weights_fp(args)\n    target_grid_fp = get_target_grid_fp(args)\n    weights = reconstruct_weights(weights_fp)\n    grid = xr.open_zarr(target_grid_fp)\n    if dataset == \"gpm_imerg\":\n        src = f'earthaccess_data/{args[\"filename\"][:-4]}.json'\n    else:\n        src = f'earthaccess_data/{args[\"filename\"][:-3]}.json'\n    s3_fs = earthaccess.get_s3fs_session(daac=args[\"daac\"])\n    storage_options = s3_fs.storage_options.copy()\n    fsspec_caching = {\n        \"cache_type\": \"none\",\n    }\n    fs = fsspec.filesystem(\"reference\", fo=src, **fsspec_caching)\n    m = fs.get_mapper(\"\")\n    da = xr.open_dataset(\n        m,\n        engine=\"kerchunk\",\n        chunks={},\n        storage_options=storage_options,\n    )[args[\"variable\"]]\n    regridder = xe.Regridder(\n        da,\n        grid,\n        \"nearest_s2d\",\n        periodic=True,\n        extrap_method=\"nearest_s2d\",\n        ignore_degenerate=True,\n        reuse_weights=True,\n        weights=weights,\n    )\n    return regridder(da)\n\n\nif __name__ == \"__main__\":\n    if \"get_ipython\" in dir():\n        da = regrid(\"gpm_imerg\")\n    else:\n        parser = argparse.ArgumentParser(description=\"Set environment for the script.\")\n        parser.add_argument(\n            \"--dataset\",\n            default=\"gpm_imerg\",\n            help=\"Dataset to resample.\",\n            choices=[\"gpm_imerg\", \"mursst\"],\n        )\n        parser.add_argument(\n            \"--gen-weights\",\n            default=False,\n            help=\"Generate weights\",\n            action=argparse.BooleanOptionalAction,\n        )\n        user_args = parser.parse_args()\n        if user_args.gen_weights:\n            generate_weights(user_args.dataset)\n        da = regrid(user_args.dataset)"
  },
  {
    "objectID": "examples/resample-xesmfcached-h5netcdf-local.html",
    "href": "examples/resample-xesmfcached-h5netcdf-local.html",
    "title": "XESMF with H5NetCDF and pre-generated weights",
    "section": "",
    "text": "Requires the upcoming ESMF 8.7 release for high-resolution datasets - https://github.com/pangeo-data/xESMF/issues/380\n\nimport argparse\nimport itertools\n\nimport fsspec\nimport numpy as np\nimport pyproj\nimport rasterio.transform\nimport xarray as xr\nimport xesmf as xe\nfrom common import earthaccess_args\n\n\ndef make_grid_ds() -&gt; xr.Dataset:\n    \"\"\"\n    Modified from ndpyramid - https://github.com/carbonplan/ndpyramid\n    \"\"\"\n    dstSRS = \"EPSG:3857\"\n    width = height = 256\n    te = [\n        -20037508.342789244,\n        -20037508.342789244,\n        20037508.342789244,\n        20037508.342789244,\n    ]\n\n    transform = rasterio.transform.Affine.translation(\n        te[0], te[3]\n    ) * rasterio.transform.Affine.scale((te[2] * 2) / width, (te[1] * 2) / height)\n\n    p = pyproj.Proj(dstSRS)\n\n    grid_shape = (height, width)\n    bounds_shape = (height + 1, width + 1)\n\n    xs = np.empty(grid_shape)\n    ys = np.empty(grid_shape)\n    lat = np.empty(grid_shape)\n    lon = np.empty(grid_shape)\n    lat_b = np.zeros(bounds_shape)\n    lon_b = np.zeros(bounds_shape)\n\n    # calc grid cell center coordinates\n    ii, jj = np.meshgrid(np.arange(height) + 0.5, np.arange(width) + 0.5)\n    for i, j in itertools.product(range(grid_shape[0]), range(grid_shape[1])):\n        locs = [ii[i, j], jj[i, j]]\n        xs[i, j], ys[i, j] = transform * locs\n        lon[i, j], lat[i, j] = p(xs[i, j], ys[i, j], inverse=True)\n\n    # calc grid cell bounds\n    iib, jjb = np.meshgrid(np.arange(height + 1), np.arange(width + 1))\n    for i, j in itertools.product(range(bounds_shape[0]), range(bounds_shape[1])):\n        locs = [iib[i, j], jjb[i, j]]\n        x, y = transform * locs\n        lon_b[i, j], lat_b[i, j] = p(x, y, inverse=True)\n\n    return xr.Dataset(\n        {\n            \"x\": xr.DataArray(xs[0, :], dims=[\"x\"]),\n            \"y\": xr.DataArray(ys[:, 0], dims=[\"y\"]),\n            \"lat\": xr.DataArray(lat, dims=[\"y\", \"x\"]),\n            \"lon\": xr.DataArray(lon, dims=[\"y\", \"x\"]),\n            \"lat_b\": xr.DataArray(lat_b, dims=[\"y_b\", \"x_b\"]),\n            \"lon_b\": xr.DataArray(lon_b, dims=[\"y_b\", \"x_b\"]),\n        },\n    )\n\n\ndef xesmf_weights_to_xarray(regridder) -&gt; xr.Dataset:\n    \"\"\"\n    From ndpyramid - https://github.com/carbonplan/ndpyramid\n    \"\"\"\n    w = regridder.weights.data\n    dim = \"n_s\"\n    ds = xr.Dataset(\n        {\n            \"S\": (dim, w.data),\n            \"col\": (dim, w.coords[1, :] + 1),\n            \"row\": (dim, w.coords[0, :] + 1),\n        }\n    )\n    ds.attrs = {\"n_in\": regridder.n_in, \"n_out\": regridder.n_out}\n    return ds\n\n\ndef _reconstruct_xesmf_weights(ds_w):\n    \"\"\"\n    Reconstruct weights into format that xESMF understands\n\n    From ndpyramid - https://github.com/carbonplan/ndpyramid\n    \"\"\"\n    import sparse\n    import xarray as xr\n\n    col = ds_w[\"col\"].values - 1\n    row = ds_w[\"row\"].values - 1\n    s = ds_w[\"S\"].values\n    n_out, n_in = ds_w.attrs[\"n_out\"], ds_w.attrs[\"n_in\"]\n    crds = np.stack([row, col])\n    return xr.DataArray(\n        sparse.COO(crds, s, (n_out, n_in)), dims=(\"out_dim\", \"in_dim\"), name=\"weights\"\n    )\n\n\ndef reconstruct_weights(weights_fp):\n    return _reconstruct_xesmf_weights(xr.open_zarr(weights_fp))\n\n\ndef get_weights_fp(earthaccess_args):\n    return (\n        \"s3://nasa-veda-scratch/test-weight-caching/\"\n        + earthaccess_args[\"filename\"][:-4]\n        + \"_weights.zarr\"\n    )\n\n\ndef get_target_grid_fp(earthaccess_args):\n    return (\n        \"s3://nasa-veda-scratch/test-weight-caching/\"\n        + earthaccess_args[\"filename\"][:-4]\n        + \"_target.zarr\"\n    )\n\n\ndef generate_weights(dataset):\n    args = earthaccess_args[dataset]\n    weights_fp = get_weights_fp(args)\n    target_grid_fp = get_target_grid_fp(args)\n    src = f'earthaccess_data/{args[\"filename\"]}'\n    target_grid = make_grid_ds()\n    target_grid.to_zarr(target_grid_fp, mode=\"w\")\n    fs = fsspec.filesystem(\"file\")\n    with fs.open(src) as f:\n        da = xr.open_dataset(f, engine=\"h5netcdf\", chunks={}, mask_and_scale=True)[\n            args[\"variable\"]\n        ]\n        regridder = xe.Regridder(\n            da,\n            target_grid,\n            \"nearest_s2d\",\n            periodic=True,\n            extrap_method=\"nearest_s2d\",\n            ignore_degenerate=True,\n        )\n        weights = xesmf_weights_to_xarray(regridder)\n        weights.to_zarr(weights_fp, mode=\"w\")\n\n\ndef regrid(dataset):\n    args = earthaccess_args[dataset]\n    weights_fp = get_weights_fp(args)\n    target_grid_fp = get_target_grid_fp(args)\n    weights = reconstruct_weights(weights_fp)\n    grid = xr.open_zarr(target_grid_fp)\n    src = f'earthaccess_data/{args[\"filename\"]}'\n    fs = fsspec.filesystem(\"file\")\n    with fs.open(src) as f:\n        da = xr.open_dataset(f, engine=\"h5netcdf\", mask_and_scale=True)[\n            args[\"variable\"]\n        ]\n        regridder = xe.Regridder(\n            da,\n            grid,\n            \"nearest_s2d\",\n            periodic=True,\n            extrap_method=\"nearest_s2d\",\n            ignore_degenerate=True,\n            reuse_weights=True,\n            weights=weights,\n        )\n        return regridder(da)\n\n\nif __name__ == \"__main__\":\n    if \"get_ipython\" in dir():\n        da = regrid(\"gpm_imerg\")\n    else:\n        parser = argparse.ArgumentParser(description=\"Set environment for the script.\")\n        parser.add_argument(\n            \"--dataset\",\n            default=\"gpm_imerg\",\n            help=\"Dataset to resample.\",\n            choices=[\"gpm_imerg\", \"mursst\"],\n        )\n        parser.add_argument(\n            \"--gen-weights\",\n            default=False,\n            help=\"Generate weights\",\n            action=argparse.BooleanOptionalAction,\n        )\n        user_args = parser.parse_args()\n        if user_args.gen_weights:\n            generate_weights(user_args.dataset)\n        da = regrid(user_args.dataset)"
  },
  {
    "objectID": "examples/resample-xesmf-h5netcdf-local.html",
    "href": "examples/resample-xesmf-h5netcdf-local.html",
    "title": "XESMF with H5NetCDF",
    "section": "",
    "text": "Requires the upcoming ESMF 8.7 release - https://github.com/pangeo-data/xESMF/issues/380\n\nimport argparse\nimport itertools\n\nimport fsspec\nimport numpy as np\nimport pyproj\nimport rasterio.transform\nimport xarray as xr\nimport xesmf as xe\nfrom common import earthaccess_args\n\n\nSetup dataset arguments\n\ndef make_grid_ds() -&gt; xr.Dataset:\n    \"\"\"\n    Modified from ndpyramid - https://github.com/carbonplan/ndpyramid\n    \"\"\"\n    dstSRS = \"EPSG:3857\"\n    width = height = 256\n    te = [\n        -20037508.342789244,\n        -20037508.342789244,\n        20037508.342789244,\n        20037508.342789244,\n    ]\n\n    transform = rasterio.transform.Affine.translation(\n        te[0], te[3]\n    ) * rasterio.transform.Affine.scale((te[2] * 2) / width, (te[1] * 2) / height)\n\n    p = pyproj.Proj(dstSRS)\n\n    grid_shape = (height, width)\n    bounds_shape = (height + 1, width + 1)\n\n    xs = np.empty(grid_shape)\n    ys = np.empty(grid_shape)\n    lat = np.empty(grid_shape)\n    lon = np.empty(grid_shape)\n    lat_b = np.zeros(bounds_shape)\n    lon_b = np.zeros(bounds_shape)\n\n    # calc grid cell center coordinates\n    ii, jj = np.meshgrid(np.arange(height) + 0.5, np.arange(width) + 0.5)\n    for i, j in itertools.product(range(grid_shape[0]), range(grid_shape[1])):\n        locs = [ii[i, j], jj[i, j]]\n        xs[i, j], ys[i, j] = transform * locs\n        lon[i, j], lat[i, j] = p(xs[i, j], ys[i, j], inverse=True)\n\n    # calc grid cell bounds\n    iib, jjb = np.meshgrid(np.arange(height + 1), np.arange(width + 1))\n    for i, j in itertools.product(range(bounds_shape[0]), range(bounds_shape[1])):\n        locs = [iib[i, j], jjb[i, j]]\n        x, y = transform * locs\n        lon_b[i, j], lat_b[i, j] = p(x, y, inverse=True)\n\n    return xr.Dataset(\n        {\n            \"x\": xr.DataArray(xs[0, :], dims=[\"x\"]),\n            \"y\": xr.DataArray(ys[:, 0], dims=[\"y\"]),\n            \"lat\": xr.DataArray(lat, dims=[\"y\", \"x\"]),\n            \"lon\": xr.DataArray(lon, dims=[\"y\", \"x\"]),\n            \"lat_b\": xr.DataArray(lat_b, dims=[\"y_b\", \"x_b\"]),\n            \"lon_b\": xr.DataArray(lon_b, dims=[\"y_b\", \"x_b\"]),\n        },\n    )\n\n\ndef regrid(dataset):\n    args = earthaccess_args[dataset]\n    src = f'earthaccess_data/{args[\"filename\"]}'\n    target_grid = make_grid_ds()\n    fs = fsspec.filesystem(\"file\")\n    with fs.open(src) as f:\n        da = xr.open_dataset(f, engine=\"h5netcdf\", chunks={}, mask_and_scale=True)[\n            args[\"variable\"]\n        ]\n        regridder = xe.Regridder(\n            da,\n            target_grid,\n            \"nearest_s2d\",\n            periodic=True,\n            extrap_method=\"nearest_s2d\",\n            ignore_degenerate=True,\n        )\n        return regridder(da)\n\n\nif __name__ == \"__main__\":\n    if \"get_ipython\" in dir():\n        da = regrid(\"gpm_imerg\")\n    else:\n        parser = argparse.ArgumentParser(description=\"Set environment for the script.\")\n        parser.add_argument(\n            \"--dataset\",\n            default=\"mursst\",\n            help=\"Dataset to resample.\",\n            choices=[\"gpm_imerg\", \"mursst\"],\n        )\n        user_args = parser.parse_args()\n        da = regrid(user_args.dataset)"
  },
  {
    "objectID": "examples/resample-rioxarray-netcdf-vsis3.html",
    "href": "examples/resample-rioxarray-netcdf-vsis3.html",
    "title": "Rasterio with NetCDF, VSIS3, and earthaccess",
    "section": "",
    "text": "import argparse\n\nimport rasterio as rio\nimport rioxarray as rx\nfrom common import earthaccess_args\nfrom rasterio.session import AWSSession\nfrom rasterio.warp import calculate_default_transform\n\n\ndef configure_auth(dataset):\n    import boto3\n    import earthaccess\n\n    auth = earthaccess.login()\n    s3_credentials = auth.get_s3_credentials(earthaccess_args[dataset][\"daac\"])\n    session = boto3.Session(\n        aws_access_key_id=s3_credentials[\"accessKeyId\"],\n        aws_secret_access_key=s3_credentials[\"secretAccessKey\"],\n        aws_session_token=s3_credentials[\"sessionToken\"],\n        region_name=\"us-west-2\",\n    )\n    rio_env = rio.Env(\n        AWSSession(session),\n    )\n    rio_env.__enter__()\n    return rio_env\n\n\ndef warp_resample(dataset):\n    args = earthaccess_args[dataset]\n    input_uri = f'{args[\"folder\"]}/{args[\"filename\"]}'\n    src = f'NETCDF:/vsis3/{args[\"bucket\"]}/{input_uri}:{args[\"variable\"]}'\n    dstSRS = \"EPSG:3857\"\n    srcSRS = \"EPSG:4326\"\n    width = height = 256\n    te = [\n        -20037508.342789244,\n        -20037508.342789244,\n        20037508.342789244,\n        20037508.342789244,\n    ]\n\n    da = rx.open_rasterio(src, mask_and_scale=True)\n    if dataset == \"gpm_imerg\":\n        raise Exception(\"NETCDF reader does not properly parse GPM IMERG coordinates\")\n    da = da.rio.write_crs(srcSRS)\n    da = da.rio.clip_box(\n        *te,\n        crs=dstSRS,\n    )\n    dst_transform, w, h = calculate_default_transform(\n        srcSRS,\n        dstSRS,\n        da.rio.width,\n        da.rio.height,\n        *da.rio.bounds(),\n        dst_width=width,\n        dst_height=height,\n    )\n    return da.rio.reproject(dstSRS, shape=(h, w), transform=dst_transform)\n\n\nif __name__ == \"__main__\":\n    if \"get_ipython\" in dir():\n        da = warp_resample(\"gpm_imerg\")\n    else:\n        parser = argparse.ArgumentParser(description=\"Set environment for the script.\")\n        parser.add_argument(\n            \"--dataset\",\n            default=\"mursst\",\n            help=\"Dataset to resample.\",\n            choices=[\"gpm_imerg\", \"mursst\"],\n        )\n        user_args = parser.parse_args()\n        rio_env = configure_auth(user_args.dataset)\n        da = warp_resample(user_args.dataset)\n        rio_env.__exit__()",
    "crumbs": [
      "Resampling libraries",
      "Rioxarray",
      "NetCDF Driver + vsis3"
    ]
  },
  {
    "objectID": "examples/resample-rioxarray-h5netcdf-.html",
    "href": "examples/resample-rioxarray-h5netcdf-.html",
    "title": "Rioxarray with H5NetCDF and earthaccess",
    "section": "",
    "text": "import argparse\n\nimport earthaccess\nimport xarray as xr\nfrom common import earthaccess_args\nfrom rasterio.warp import calculate_default_transform\n\n\ndef warp_resample(dataset):\n    args = earthaccess_args[dataset]\n    input_uri = f'{args[\"folder\"]}/{args[\"filename\"]}'\n    src = f's3://{args[\"bucket\"]}/{input_uri}'\n    dstSRS = \"EPSG:3857\"\n    srcSRS = \"EPSG:4326\"\n    width = height = 256\n    te = [\n        -20037508.342789244,\n        -20037508.342789244,\n        20037508.342789244,\n        20037508.342789244,\n    ]\n\n    fs = earthaccess.get_s3fs_session(daac=args[\"daac\"])\n    fsspec_caching = {\n        \"cache_type\": \"none\",\n    }\n    with fs.open(src, **fsspec_caching) as f:\n        da = xr.open_dataset(f, engine=\"h5netcdf\", mask_and_scale=True)[\n            args[\"variable\"]\n        ]\n        if dataset == \"gpm_imerg\":\n            da = da.rename({\"lon\": \"x\", \"lat\": \"y\"}).transpose(\"time\", \"y\", \"x\")\n        da = da.rio.write_crs(srcSRS)\n        da = da.rio.clip_box(\n            *te,\n            crs=dstSRS,\n        )\n        dst_transform, w, h = calculate_default_transform(\n            srcSRS,\n            dstSRS,\n            da.rio.width,\n            da.rio.height,\n            *da.rio.bounds(),\n            dst_width=width,\n            dst_height=height,\n        )\n        return da.rio.reproject(dstSRS, shape=(h, w), transform=dst_transform)\n\n\nif __name__ == \"__main__\":\n    if \"get_ipython\" in dir():\n        da = warp_resample(\"gpm_imerg\")\n    else:\n        parser = argparse.ArgumentParser(description=\"Set environment for the script.\")\n        parser.add_argument(\n            \"--dataset\",\n            default=\"mursst\",\n            help=\"Dataset to resample.\",\n            choices=[\"gpm_imerg\", \"mursst\"],\n        )\n        user_args = parser.parse_args()\n        da = warp_resample(user_args.dataset)"
  },
  {
    "objectID": "examples/resample-pyresample-h5netcdf-.html",
    "href": "examples/resample-pyresample-h5netcdf-.html",
    "title": "Pyresample with H5NetCDF and earthaccess",
    "section": "",
    "text": "import earthaccess\nimport xarray as xr\nfrom common import earthaccess_args\nfrom pyresample.area_config import create_area_def\nfrom pyresample.gradient import block_nn_interpolator, gradient_resampler_indices_block\nfrom pyresample.resampler import resample_blocks\n\n\ndataset = \"gpm_imerg\"\nfilename = earthaccess_args[dataset][\"filename\"]\nbucket = earthaccess_args[dataset][\"bucket\"]\nfolder = earthaccess_args[dataset][\"folder\"]\nvariable = earthaccess_args[dataset][\"variable\"]\n\n\ndef warp_resample():\n    input_uri = f\"{folder}/{filename}\"\n    src = f\"s3://{bucket}/{input_uri}\"\n    dstSRS = \"EPSG:3857\"\n    srcSRS = \"EPSG:4326\"\n    width = height = 256\n    te = [\n        -20037508.342789244,\n        -20037508.342789244,\n        20037508.342789244,\n        20037508.342789244,\n    ]\n    earthaccess.login()\n    fs = earthaccess.get_s3fs_session(daac=\"PODAAC\")\n    fsspec_caching = {\n        \"cache_type\": \"none\",\n    }\n    with fs.open(src, **fsspec_caching) as f:\n        da = xr.open_dataset(f, engine=\"h5netcdf\", chunks={})[variable]\n        da = da.chunk({\"time\": -1, \"lat\": 4000, \"lon\": 4000})\n        target_area_def = create_area_def(\n            area_id=1,\n            projection=dstSRS,\n            shape=(height, width),\n            area_extent=te,\n        )\n        source_area_def = create_area_def(\n            area_id=2,\n            projection=srcSRS,\n            shape=(da.sizes[\"lat\"], da.sizes[\"lon\"]),\n            area_extent=[-179.995, 89.995, 180.005, -89.995],\n        )\n        indices_xy = resample_blocks(\n            gradient_resampler_indices_block,\n            source_area_def,\n            [],\n            target_area_def,\n            chunk_size=(1, height, width),\n            dtype=float,\n        )\n        resampled = resample_blocks(\n            block_nn_interpolator,\n            source_area_def,\n            [da.data],\n            target_area_def,\n            dst_arrays=[indices_xy],\n            chunk_size=(1, height, width),\n            dtype=da.dtype,\n        )\n        return resampled.compute()\n\n\nif __name__ == \"__main__\":\n    da = warp_resample()",
    "crumbs": [
      "Resampling libraries",
      "Pyresample",
      "h5netcdf Driver"
    ]
  },
  {
    "objectID": "examples/resample-odc-h5netcdf-.html",
    "href": "examples/resample-odc-h5netcdf-.html",
    "title": "ODC-geo with H5NetCDF and earthaccess",
    "section": "",
    "text": "import argparse\n\nimport earthaccess\nimport xarray as xr\nfrom common import earthaccess_args\nfrom odc.geo.geobox import GeoBox\nfrom odc.geo.xr import xr_reproject\n\n\ndef warp_resample(dataset):\n    args = earthaccess_args[dataset]\n    input_uri = f'{args[\"folder\"]}/{args[\"filename\"]}'\n    src = f's3://{args[\"bucket\"]}/{input_uri}'\n    dstSRS = \"EPSG:3857\"\n    srcSRS = \"EPSG:4326\"\n    width = height = 256\n    te = [\n        -20037508.342789244,\n        -20037508.342789244,\n        20037508.342789244,\n        20037508.342789244,\n    ]\n    earthaccess.login()\n    fs = earthaccess.get_s3fs_session(daac=args[\"daac\"])\n    fsspec_caching = {\n        \"cache_type\": \"none\",\n    }\n    with fs.open(src, **fsspec_caching) as f:\n        gbox = GeoBox.from_bbox(te, dstSRS, shape=(height, width))\n        da = xr.open_dataset(f, engine=\"h5netcdf\")[args[\"variable\"]]\n        if dataset == \"gpm_imerg\":\n            da = (\n                da.rename({\"lon\": \"x\", \"lat\": \"y\"})\n                .transpose(\"time\", \"y\", \"x\")\n                .squeeze()\n            )\n        da = da.odc.assign_crs(srcSRS)\n        return xr_reproject(da, gbox)\n\n\nif __name__ == \"__main__\":\n    if \"get_ipython\" in dir():\n        da = warp_resample(\"gpm_imerg\")\n    else:\n        parser = argparse.ArgumentParser(description=\"Set environment for the script.\")\n        parser.add_argument(\n            \"--dataset\",\n            default=\"mursst\",\n            help=\"Dataset to resample.\",\n            choices=[\"gpm_imerg\", \"mursst\"],\n        )\n        user_args = parser.parse_args()\n        da = warp_resample(user_args.dataset)",
    "crumbs": [
      "Resampling libraries",
      "Open Data Cube",
      "NetCDF Driver + vsis3"
    ]
  },
  {
    "objectID": "examples/resample-gdal-netcdf-vsis3.html",
    "href": "examples/resample-gdal-netcdf-vsis3.html",
    "title": "GDAL with NetCDF, VSIS3, and earthaccess",
    "section": "",
    "text": "from common import earthaccess_args\nfrom osgeo import gdal\nfrom pyproj.crs import CRS\n\n\ngdal.UseExceptions()\n\n\ndataset = \"gpm_imerg\"\nfilename = earthaccess_args[dataset][\"filename\"]\nbucket = earthaccess_args[dataset][\"bucket\"]\nfolder = earthaccess_args[dataset][\"folder\"]\nvariable = earthaccess_args[dataset][\"variable\"]\n\n\ndef configure_auth():\n    import earthaccess\n\n    auth = earthaccess.login()\n    s3_credentials = auth.get_s3_credentials(\"PODAAC\")\n    gdal.SetConfigOption(\"AWS_REGION\", \"us-west-2\")\n    gdal.SetConfigOption(\"AWS_SECRET_ACCESS_KEY\", s3_credentials[\"secretAccessKey\"])\n    gdal.SetConfigOption(\"AWS_ACCESS_KEY_ID\", s3_credentials[\"accessKeyId\"])\n    gdal.SetConfigOption(\"AWS_SESSION_TOKEN\", s3_credentials[\"sessionToken\"])\n\n\ndef warp_resample():\n    src = f\"NETCDF:/vsis3/{bucket}/{folder}/{filename}:{variable}\"\n    output = \"\"\n    output_format = \"MEM\"\n    dstSRS = \"EPSG:3857\"\n\n    width = height = 256\n    te = [\n        -20037508.342789244,\n        -20037508.342789244,\n        20037508.342789244,\n        20037508.342789244,\n    ]\n    gt = [\n        te[0],\n        (te[2] - te[0]) / width,\n        0,\n        te[3],\n        0,\n        -(te[3] - te[1]) / height,\n    ]\n    output_crs = CRS(dstSRS).to_wkt()\n\n    output_ds = gdal.GetDriverByName(output_format).Create(\n        output, width, height, 1, gdal.GDT_Byte\n    )\n    output_ds.SetProjection(output_crs)\n    output_ds.SetGeoTransform(gt)\n    input_ds = gdal.Open(src)\n    return gdal.Warp(output_ds, input_ds)\n\n\nif __name__ == \"__main__\":\n    configure_auth()\n    arr = warp_resample()",
    "crumbs": [
      "Resampling libraries",
      "GDAL Python API",
      "NetCDF Driver + vsis3 (remote)"
    ]
  },
  {
    "objectID": "examples/process-results.html",
    "href": "examples/process-results.html",
    "title": "Process results",
    "section": "",
    "text": "import hvplot.pandas  # noqa\nfrom utils import process_results\ndf = process_results(\"results\").sort_values([\"peak memory (GB)\"])",
    "crumbs": [
      "Profiling results",
      "Memory and time usage (MURSST)"
    ]
  },
  {
    "objectID": "examples/process-results.html#show-memory-and-time-for-warp-resampling-dataset",
    "href": "examples/process-results.html#show-memory-and-time-for-warp-resampling-dataset",
    "title": "Process results",
    "section": "Show memory and time for warp resampling dataset",
    "text": "Show memory and time for warp resampling dataset\n\ndf_resample = df[df[\"task\"] == \"resample\"]\ndf_resample.style.background_gradient(cmap=\"YlOrRd\")\n\n\n\n\n\n\n \ntask\nmethod\ndriver\nvirtual\npeak memory (GB)\nduration (s)\n\n\n\n\n8\nresample\ngdal\nnetcdf\nlocal\n1.877886\n14.857080\n\n\n10\nresample\ngdal\nvrt\nlocal\n1.877896\n10.501181\n\n\n9\nresample\ngdal\nnetcdf\nvsis3\n2.267324\n87.021567\n\n\n13\nresample\nrasterio\nnetcdf\nvsis3\n3.295342\n95.873359\n\n\n14\nresample\nrioxarray\nnetcdf\nvsis3\n4.506330\n99.652136\n\n\n11\nresample\nodc\nh5netcdf\n\n12.441574\n41.386587\n\n\n12\nresample\npyresample\nh5netcdf\n\n39.164460\n46.934369",
    "crumbs": [
      "Profiling results",
      "Memory and time usage (MURSST)"
    ]
  },
  {
    "objectID": "examples/load-xarray-zarr-kerchunk.html",
    "href": "examples/load-xarray-zarr-kerchunk.html",
    "title": "Xarray with zarr and kerchunk",
    "section": "",
    "text": "import earthaccess\nimport fsspec\nimport xarray as xr\nfrom common import earthaccess_args\n\n\ndataset = \"gpm_imerg\"\nfilename = earthaccess_args[dataset][\"filename\"]\nbucket = earthaccess_args[dataset][\"bucket\"]\nfolder = earthaccess_args[dataset][\"folder\"]\nvariable = earthaccess_args[dataset][\"variable\"]\ndaac = earthaccess_args[dataset][\"daac\"]\n\n\ndef load_data():\n    if \".nc4\" in filename:\n        src = f\"earthaccess_data/{filename[:-4]}.json\"\n    else:\n        src = f\"earthaccess_data/{filename[:-3]}.json\"\n    earthaccess.login()\n    s3_fs = earthaccess.get_s3fs_session(daac=daac)\n    storage_options = s3_fs.storage_options.copy()\n    fsspec_caching = {\n        \"cache_type\": \"none\",\n    }\n    fs = fsspec.filesystem(\"reference\", fo=src, **fsspec_caching)\n    m = fs.get_mapper(\"\")\n    da = xr.open_dataset(\n        m,\n        engine=\"kerchunk\",\n        chunks={},\n        storage_options=storage_options,\n    )[variable]\n    return da.load()\n\n\nif __name__ == \"__main__\":\n    da = load_data()",
    "crumbs": [
      "Loading data",
      "Xarray",
      "Zarr via kerchunk"
    ]
  },
  {
    "objectID": "examples/load-rioxarray-netcdf-vsis3.html",
    "href": "examples/load-rioxarray-netcdf-vsis3.html",
    "title": "Rioxarray with NetCDF, VSIS3, and earthaccess",
    "section": "",
    "text": "import rasterio as rio\nimport rioxarray as rx\nfrom common import earthaccess_args\nfrom rasterio.session import AWSSession\n\n\ndataset = \"gpm_imerg\"\nfilename = earthaccess_args[dataset][\"filename\"]\nbucket = earthaccess_args[dataset][\"bucket\"]\nfolder = earthaccess_args[dataset][\"folder\"]\nvariable = earthaccess_args[dataset][\"variable\"]\ndaac = earthaccess_args[dataset][\"daac\"]\n\n\ndef configure_auth():\n    import boto3\n    import earthaccess\n\n    auth = earthaccess.login()\n    s3_credentials = auth.get_s3_credentials(daac)\n    session = boto3.Session(\n        aws_access_key_id=s3_credentials[\"accessKeyId\"],\n        aws_secret_access_key=s3_credentials[\"secretAccessKey\"],\n        aws_session_token=s3_credentials[\"sessionToken\"],\n        region_name=\"us-west-2\",\n    )\n    rio_env = rio.Env(\n        AWSSession(session),\n    )\n    rio_env.__enter__()\n    return rio_env\n\n\ndef load_data():\n    input_uri = f\"{folder}/{filename}\"\n    src = f\"NETCDF:/vsis3/{bucket}/{input_uri}:{variable}\"\n    return rx.open_rasterio(src, mask_and_scale=True).load()\n\n\nif __name__ == \"__main__\":\n    rio_env = configure_auth()\n    da = load_data()\n    rio_env.__exit__()",
    "crumbs": [
      "Loading data",
      "Rioxarray",
      "NetCDF Driver + vsis3"
    ]
  },
  {
    "objectID": "examples/load-rasterio-netcdf-local.html",
    "href": "examples/load-rasterio-netcdf-local.html",
    "title": "Rasterio with NetCDF, VSIS3, and earthaccess",
    "section": "",
    "text": "import numpy as np\nimport rasterio\nfrom common import earthaccess_args\n\n\ndataset = \"gpm_imerg\"\nfilename = earthaccess_args[dataset][\"filename\"]\nbucket = earthaccess_args[dataset][\"bucket\"]\nfolder = earthaccess_args[dataset][\"folder\"]\nvariable = earthaccess_args[dataset][\"variable\"]\nscale = earthaccess_args[dataset][\"scale\"]\ndaac = earthaccess_args[dataset][\"daac\"]\n\n\ndef open_data():\n    src = f\"NETCDF:earthaccess_data/{filename}:{variable}\"\n    with rasterio.open(src) as src_da:\n        ma = src_da.read(1, masked=True)\n        ma = ma.astype(\"float32\", casting=\"unsafe\")\n        if scale:\n            np.multiply(ma, src_da.scales[0], out=ma, casting=\"unsafe\")\n            np.add(ma, src_da.offsets[0], out=ma, casting=\"unsafe\")\n    return ma.filled(fill_value=np.nan)\n\n\nif __name__ == \"__main__\":\n    da = open_data()",
    "crumbs": [
      "Loading data",
      "Rasterio",
      "NetCDF Driver"
    ]
  },
  {
    "objectID": "examples/load-gdal-netcdf-vsis3.html",
    "href": "examples/load-gdal-netcdf-vsis3.html",
    "title": "GDAL with NetCDF and earthaccess",
    "section": "",
    "text": "import numpy as np\nfrom common import earthaccess_args\nfrom osgeo import gdal\n\n\ngdal.UseExceptions()\n\n\ndataset = \"gpm_imerg\"\nfilename = earthaccess_args[dataset][\"filename\"]\nbucket = earthaccess_args[dataset][\"bucket\"]\nfolder = earthaccess_args[dataset][\"folder\"]\nvariable = earthaccess_args[dataset][\"variable\"]\nscale = earthaccess_args[dataset][\"scale\"]\ndaac = earthaccess_args[dataset][\"daac\"]\n\n\ndef configure_auth():\n    import earthaccess\n\n    auth = earthaccess.login()\n    s3_credentials = auth.get_s3_credentials(daac)\n    gdal.SetConfigOption(\"AWS_REGION\", \"us-west-2\")\n    gdal.SetConfigOption(\"AWS_SECRET_ACCESS_KEY\", s3_credentials[\"secretAccessKey\"])\n    gdal.SetConfigOption(\"AWS_ACCESS_KEY_ID\", s3_credentials[\"accessKeyId\"])\n    gdal.SetConfigOption(\"AWS_SESSION_TOKEN\", s3_credentials[\"sessionToken\"])\n\n\ndef load_data():\n    src = f\"NETCDF:/vsis3/{bucket}/{folder}/{filename}:{variable}\"\n    ds = gdal.Open(src)\n    band = ds.GetRasterBand(1)\n    arr = band.ReadAsArray().astype(\"float32\", casting=\"unsafe\")\n    mask = band.GetMaskBand().ReadAsArray()\n    ma = np.ma.masked_array(arr, np.logical_not(mask), fill_value=np.nan)\n    if scale:\n        np.multiply(ma, band.GetScale(), out=ma, casting=\"unsafe\")\n        np.add(ma, band.GetOffset(), out=ma, casting=\"unsafe\")\n    return ma.filled(fill_value=np.nan)\n\n\nif __name__ == \"__main__\":\n    configure_auth()\n    da = load_data()",
    "crumbs": [
      "Loading data",
      "GDAL Python API",
      "NetCDF Driver + vsis3 (remote)"
    ]
  },
  {
    "objectID": "examples/future-resample-xesmf-h5netcdf-.html",
    "href": "examples/future-resample-xesmf-h5netcdf-.html",
    "title": "XESMF with H5NetCDF and earthaccess",
    "section": "",
    "text": "Requires the upcoming ESMF 8.7 release - https://github.com/pangeo-data/xESMF/issues/380\n\nimport itertools\n\nimport numpy as np\nimport pyproj\nimport rasterio.transform\nimport xarray as xr\nimport xesmf as xe\nfrom common import earthaccess_args\n\n\nSetup dataset arguments\n\ndataset = \"gpm_imerg\"\ndataset_args = earthaccess_args[dataset]\nsrc = f\"s3://{dataset_args['bucket']}/{dataset_args['input_uri']}/{dataset_args['filename']}\"\nvariable = dataset_args[\"variable\"]\n\n\ndef configure_fs_auth():\n    import earthaccess\n    import s3fs\n\n    auth = earthaccess.login()\n    s3_credentials = auth.get_s3_credentials(\"PODAAC\")\n    fs = s3fs.S3FileSystem(\n        anon=False,\n        key=s3_credentials[\"accessKeyId\"],\n        secret=s3_credentials[\"secretAccessKey\"],\n        token=s3_credentials[\"sessionToken\"],\n    )\n    return fs\n\n\ndef make_grid_ds() -&gt; xr.Dataset:\n    \"\"\"\n    Modified from ndpyramid - https://github.com/carbonplan/ndpyramid\n    \"\"\"\n    dstSRS = \"EPSG:3857\"\n    width = height = 256\n    te = [\n        -20037508.342789244,\n        -20037508.342789244,\n        20037508.342789244,\n        20037508.342789244,\n    ]\n\n    transform = rasterio.transform.Affine.translation(\n        te[0], te[3]\n    ) * rasterio.transform.Affine.scale((te[2] * 2) / width, (te[1] * 2) / height)\n\n    p = pyproj.Proj(dstSRS)\n\n    grid_shape = (height, width)\n    bounds_shape = (height + 1, width + 1)\n\n    xs = np.empty(grid_shape)\n    ys = np.empty(grid_shape)\n    lat = np.empty(grid_shape)\n    lon = np.empty(grid_shape)\n    lat_b = np.zeros(bounds_shape)\n    lon_b = np.zeros(bounds_shape)\n\n    # calc grid cell center coordinates\n    ii, jj = np.meshgrid(np.arange(height) + 0.5, np.arange(width) + 0.5)\n    for i, j in itertools.product(range(grid_shape[0]), range(grid_shape[1])):\n        locs = [ii[i, j], jj[i, j]]\n        xs[i, j], ys[i, j] = transform * locs\n        lon[i, j], lat[i, j] = p(xs[i, j], ys[i, j], inverse=True)\n\n    # calc grid cell bounds\n    iib, jjb = np.meshgrid(np.arange(height + 1), np.arange(width + 1))\n    for i, j in itertools.product(range(bounds_shape[0]), range(bounds_shape[1])):\n        locs = [iib[i, j], jjb[i, j]]\n        x, y = transform * locs\n        lon_b[i, j], lat_b[i, j] = p(x, y, inverse=True)\n\n    return xr.Dataset(\n        {\n            \"x\": xr.DataArray(xs[0, :], dims=[\"x\"]),\n            \"y\": xr.DataArray(ys[:, 0], dims=[\"y\"]),\n            \"lat\": xr.DataArray(lat, dims=[\"y\", \"x\"]),\n            \"lon\": xr.DataArray(lon, dims=[\"y\", \"x\"]),\n            \"lat_b\": xr.DataArray(lat_b, dims=[\"y_b\", \"x_b\"]),\n            \"lon_b\": xr.DataArray(lon_b, dims=[\"y_b\", \"x_b\"]),\n        },\n    )\n\n\ndef regrid():\n    fs = configure_fs_auth()\n    fsspec_caching = {\n        \"cache_type\": \"none\",\n    }\n    target_grid = make_grid_ds()\n    with fs.open(src, **fsspec_caching) as f:\n        da = xr.open_dataset(f, engine=\"h5netcdf\")[variable]\n        regridder = xe.Regridder(\n            da,\n            target_grid,\n            \"nearest_s2d\",\n            periodic=True,\n            extrap_method=\"nearest_s2d\",\n            ignore_degenerate=True,\n        )\n        return regridder(da)\n\n\nif __name__ == \"__main__\":\n    ds = regrid()",
    "crumbs": [
      "WIP Resampling methods",
      "XESMF",
      "(Pending) h5netcdf Driver"
    ]
  },
  {
    "objectID": "examples/future-resample-pygmt-netcdf-local.html",
    "href": "examples/future-resample-pygmt-netcdf-local.html",
    "title": "PyGMT with NetCDF",
    "section": "",
    "text": "import pygmt\n\n\ndef reproject():\n    fp = \"earthaccess_data/20020601090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\"\n    dstSRS = \"EPSG:3857\"\n    te = [\n        -20037508.342789244,\n        -20037508.342789244,\n        20037508.342789244,\n        20037508.342789244,\n    ]  # %%\n    return pygmt.grdproject(\n        grid=fp, region=f\"{te[0]}/{te[2]}/{te[1]}/{te[3]}+ue\", projection=dstSRS\n    )\n\n\nif __name__ == \"__main__\":\n    reproject()",
    "crumbs": [
      "WIP Resampling methods",
      "PyGMT",
      "(Pending) NetCDF Driver"
    ]
  },
  {
    "objectID": "examples/future-load-geoutils-netcdf-vsis3.html",
    "href": "examples/future-load-geoutils-netcdf-vsis3.html",
    "title": "GeoUtils with NetCDF, VSIS3, and earthaccess",
    "section": "",
    "text": "import rasterio as rio\nfrom geoutils import Raster\n\n\ndef configure_auth():\n    import boto3\n    import earthaccess\n    from rasterio.session import AWSSession\n\n    auth = earthaccess.login()\n    s3_credentials = auth.get_s3_credentials(\"PODAAC\")\n    session = boto3.Session(\n        aws_access_key_id=s3_credentials[\"accessKeyId\"],\n        aws_secret_access_key=s3_credentials[\"secretAccessKey\"],\n        aws_session_token=s3_credentials[\"sessionToken\"],\n        region_name=\"us-west-2\",\n    )\n    rio_env = rio.Env(\n        AWSSession(session),\n    )\n    rio_env.__enter__()\n    return rio_env\n\n\ndef load_data():\n    bucket = \"podaac-ops-cumulus-protected\"\n    input_uri = \"MUR-JPL-L4-GLOB-v4.1/20020601090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\"\n    src = f\"NETCDF:/vsis3/{bucket}/{input_uri}:analysed_sst\"\n    da = rio.open(src)\n    da = Raster(da)\n    return da.load()\n\n\nif __name__ == \"__main__\":\n    rio_env = configure_auth()\n    da = load_data()\n    rio_env.__exit__()"
  },
  {
    "objectID": "examples/earthdata-download.html",
    "href": "examples/earthdata-download.html",
    "title": "Download and virtualize dataset",
    "section": "",
    "text": "from pathlib import Path\n\nimport earthaccess\nimport xarray as xr\nfrom common import earthaccess_args",
    "crumbs": [
      "Dataset preparation",
      "Download and virtualize dataset"
    ]
  },
  {
    "objectID": "examples/earthdata-download.html#load-results",
    "href": "examples/earthdata-download.html#load-results",
    "title": "Download and virtualize dataset",
    "section": "Load results",
    "text": "Load results\n\nds = xr.open_zarr(store, zarr_version=3, consolidated=False)\n\n\nds",
    "crumbs": [
      "Dataset preparation",
      "Download and virtualize dataset"
    ]
  },
  {
    "objectID": "examples/future-resample-odc-zarr-kerchunk.html",
    "href": "examples/future-resample-odc-zarr-kerchunk.html",
    "title": "ODC with Zarr, Kerchunk, and earthaccess",
    "section": "",
    "text": "import earthaccess\nimport fsspec\nimport xarray as xr\nfrom odc.geo.geobox import GeoBox\nfrom odc.geo.xr import xr_reproject\n\n\ndef warp_resample():\n    src = \"earthaccess_data/20020601090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.json\"\n    variable = \"analysed_sst\"\n    dstSRS = \"EPSG:3857\"\n    srcSRS = \"EPSG:4326\"\n    width = height = 256\n    te = [\n        -20037508.342789244,\n        -20037508.342789244,\n        20037508.342789244,\n        20037508.342789244,\n    ]\n    earthaccess.login()\n    s3_fs = earthaccess.get_s3fs_session(daac=\"PODAAC\")\n    storage_options = s3_fs.storage_options.copy()\n    fsspec_caching = {\n        \"cache_type\": \"none\",\n    }\n    fs = fsspec.filesystem(\"reference\", fo=src, **fsspec_caching)\n    m = fs.get_mapper(\"\")\n    da = xr.open_dataset(\n        m, engine=\"kerchunk\", chunks={}, storage_options=storage_options\n    )[variable]\n    gbox = GeoBox.from_bbox(te, dstSRS, shape=(height, width))\n    da = da.odc.assign_crs(srcSRS)\n    return xr_reproject(da, gbox)\n\n\nif __name__ == \"__main__\":\n    da, gbox = warp_resample()",
    "crumbs": [
      "WIP Resampling methods",
      "ODC",
      "(Pending) Zarr via kerchunk"
    ]
  },
  {
    "objectID": "examples/future-resample-xcube-h5netcdf-.html",
    "href": "examples/future-resample-xcube-h5netcdf-.html",
    "title": "Xcube with H5NetCDF",
    "section": "",
    "text": "import xarray as xr\nfrom xcube.core.gridmapping import GridMapping\nfrom xcube.core.resampling import resample_in_space\n\n\ndef configure_fs_auth():\n    import earthaccess\n    import s3fs\n\n    auth = earthaccess.login()\n    s3_credentials = auth.get_s3_credentials(\"PODAAC\")\n    fs = s3fs.S3FileSystem(\n        anon=False,\n        key=s3_credentials[\"accessKeyId\"],\n        secret=s3_credentials[\"secretAccessKey\"],\n        token=s3_credentials[\"sessionToken\"],\n    )\n    return fs\n\n\ndef warp_resample():\n    bucket = \"podaac-ops-cumulus-protected\"\n    input_uri = \"MUR-JPL-L4-GLOB-v4.1/20020601090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\"\n    variable = \"analysed_sst\"\n    src = f\"s3://{bucket}/{input_uri}\"\n    dstSRS = \"EPSG:3857\"\n    srcSRS = \"EPSG:4326\"\n    width = height = 256\n    te = [\n        -20037508.342789244,\n        -20037508.342789244,\n        20037508.342789244,\n        20037508.342789244,\n    ]\n    xres = (te[2] - te[0]) / width\n    yres = (te[3] - te[1]) / width\n    fs = configure_fs_auth()\n    fsspec_caching = {\n        \"cache_type\": \"none\",\n    }\n    with fs.open(src, **fsspec_caching) as f:\n        ds = xr.open_dataset(f, engine=\"h5netcdf\", chunks={})[[variable]]\n        source_gm = GridMapping.from_coords(\n            x_coords=ds.lat, y_coords=ds.lon, crs=srcSRS\n        )\n        target_gm = GridMapping.regular(\n            size=[height, width], xy_min=[te[0], te[1]], xy_res=[xres, yres], crs=dstSRS\n        )\n        return resample_in_space(ds, source_gm=source_gm, target_gm=target_gm)\n\n\n%%time\nif __name__ == \"__main__\":\n    da = warp_resample()",
    "crumbs": [
      "WIP Resampling methods",
      "XCube",
      "(Pending) h5netcdf Driver"
    ]
  },
  {
    "objectID": "examples/load-gdal-netcdf-local.html",
    "href": "examples/load-gdal-netcdf-local.html",
    "title": "GDAL with NetCDF",
    "section": "",
    "text": "import numpy as np\nfrom common import earthaccess_args\nfrom osgeo import gdal\n\n\ngdal.UseExceptions()\n\n\ndataset = \"gpm_imerg\"\nfilename = earthaccess_args[dataset][\"filename\"]\nvariable = earthaccess_args[dataset][\"variable\"]\nscale = earthaccess_args[dataset][\"scale\"]\n\n\ndef load_data():\n    src = f\"NETCDF:earthaccess_data/{filename}:{variable}\"\n    ds = gdal.Open(src)\n    band = ds.GetRasterBand(1)\n    arr = band.ReadAsArray().astype(\"float32\", casting=\"unsafe\")\n    mask = band.GetMaskBand().ReadAsArray()\n    ma = np.ma.masked_array(arr, np.logical_not(mask), fill_value=np.nan)\n    if scale:\n        np.multiply(ma, band.GetScale(), out=ma, casting=\"unsafe\")\n        np.add(ma, band.GetOffset(), out=ma, casting=\"unsafe\")\n    return ma.filled(fill_value=np.nan)\n\n\nif __name__ == \"__main__\":\n    arr = load_data()",
    "crumbs": [
      "Loading data",
      "GDAL Python API",
      "NetCDF Driver (local)"
    ]
  },
  {
    "objectID": "examples/load-gdal-vrt-local.html",
    "href": "examples/load-gdal-vrt-local.html",
    "title": "GDAL with HDF5 and VRT",
    "section": "",
    "text": "import numpy as np\nfrom common import earthaccess_args\nfrom osgeo import gdal\n\n\ngdal.UseExceptions()\n\n\ndataset = \"gpm_imerg\"\nfilename = earthaccess_args[dataset][\"filename\"]\nvariable = earthaccess_args[dataset][\"variable\"]\nscale = earthaccess_args[dataset][\"scale\"]\na_ullr = earthaccess_args[dataset][\"a_ullr\"]\n\n\ndef load_data():\n    src = f\"vrt://earthaccess_data/{filename}?a_ullr={a_ullr}&sd_name={variable}\"\n    ds = gdal.Open(src)\n    band = ds.GetRasterBand(1)\n    arr = band.ReadAsArray().astype(\"float32\", casting=\"unsafe\")\n    mask = band.GetMaskBand().ReadAsArray()\n    ma = np.ma.masked_array(arr, np.logical_not(mask), fill_value=np.nan)\n    if scale:\n        np.multiply(ma, band.GetScale(), out=ma, casting=\"unsafe\")\n        np.add(ma, band.GetOffset(), out=ma, casting=\"unsafe\")\n    return ma.filled(fill_value=np.nan)\n\n\nif __name__ == \"__main__\":\n    da = load_data()",
    "crumbs": [
      "Loading data",
      "GDAL Python API",
      "NetCDF Driver + vrt (local)"
    ]
  },
  {
    "objectID": "examples/load-rasterio-netcdf-vsis3.html",
    "href": "examples/load-rasterio-netcdf-vsis3.html",
    "title": "Rasterio with NetCDF, VSIS3, and earthaccess",
    "section": "",
    "text": "import numpy as np\nimport rasterio\nimport rasterio as rio\nfrom common import earthaccess_args\nfrom rasterio.session import AWSSession\n\n\ndataset = \"gpm_imerg\"\nfilename = earthaccess_args[dataset][\"filename\"]\nbucket = earthaccess_args[dataset][\"bucket\"]\nfolder = earthaccess_args[dataset][\"folder\"]\nvariable = earthaccess_args[dataset][\"variable\"]\nscale = earthaccess_args[dataset][\"scale\"]\ndaac = earthaccess_args[dataset][\"daac\"]\n\n\ndef configure_auth():\n    import boto3\n    import earthaccess\n\n    auth = earthaccess.login()\n    s3_credentials = auth.get_s3_credentials(daac)\n    session = boto3.Session(\n        aws_access_key_id=s3_credentials[\"accessKeyId\"],\n        aws_secret_access_key=s3_credentials[\"secretAccessKey\"],\n        aws_session_token=s3_credentials[\"sessionToken\"],\n        region_name=\"us-west-2\",\n    )\n    rio_env = rio.Env(\n        AWSSession(session),\n    )\n    rio_env.__enter__()\n    return rio_env\n\n\ndef load_data():\n    input_uri = f\"{folder}/{filename}\"\n    src = f\"NETCDF:/vsis3/{bucket}/{input_uri}:{variable}\"\n    with rasterio.open(src) as src_da:\n        ma = src_da.read(1, masked=True)\n        ma = ma.astype(\"float32\", casting=\"unsafe\")\n        np.multiply(ma, src_da.scales[0], out=ma, casting=\"unsafe\")\n        np.add(ma, src_da.offsets[0], out=ma, casting=\"unsafe\")\n    return ma.filled(fill_value=np.nan)\n\n\nif __name__ == \"__main__\":\n    rio_env = configure_auth()\n    da = load_data()\n    rio_env.__exit__()",
    "crumbs": [
      "Loading data",
      "Rasterio",
      "NetCDF Driver + vsis3"
    ]
  },
  {
    "objectID": "examples/load-xarray-h5netcdf-.html",
    "href": "examples/load-xarray-h5netcdf-.html",
    "title": "Xarray with h5netcdf and earthaccess",
    "section": "",
    "text": "import earthaccess\nimport xarray as xr\nfrom common import earthaccess_args\n\n\ndataset = \"gpm_imerg\"\nfilename = earthaccess_args[dataset][\"filename\"]\nbucket = earthaccess_args[dataset][\"bucket\"]\nfolder = earthaccess_args[dataset][\"folder\"]\nvariable = earthaccess_args[dataset][\"variable\"]\nmask_and_scale = earthaccess_args[dataset][\"mask_and_scale\"]\ndaac = earthaccess_args[dataset][\"daac\"]\n\n\ndef load_data():\n    input_uri = f\"{folder}/{filename}\"\n    src = f\"s3://{bucket}/{input_uri}\"\n    earthaccess.login()\n    fs = earthaccess.get_s3fs_session(daac=daac)\n    fsspec_caching = {\n        \"cache_type\": \"none\",\n    }\n    with fs.open(src, **fsspec_caching) as f:\n        da = xr.open_dataset(f, engine=\"h5netcdf\", mask_and_scale=mask_and_scale)[\n            variable\n        ]\n        return da.load()\n\n\nif __name__ == \"__main__\":\n    da = load_data()",
    "crumbs": [
      "Loading data",
      "Xarray",
      "h5netcdf Driver"
    ]
  },
  {
    "objectID": "examples/process-gpm-results.html",
    "href": "examples/process-gpm-results.html",
    "title": "Process results for GPM IMERG",
    "section": "",
    "text": "import hvplot.pandas  # noqa\nfrom utils import process_results\ndf = process_results(\"results/2024-10-16\").sort_values([\"peak memory (GB)\"])\n\nmemray-gpm_imerg-resample-odc-h5netcdf-.json\nmemray-gpm_imerg-resample-odc-h5netcdf-local.json\nmemray-gpm_imerg-resample-rioxarray-h5netcdf-.json\nmemray-gpm_imerg-resample-rioxarray-h5netcdf-local.json\nmemray-gpm_imerg-resample-xesmf-h5netcdf-.json\nmemray-gpm_imerg-resample-xesmf-h5netcdf-local.json\nmemray-gpm_imerg-resample-xesmfcached-h5netcdf-.json\nmemray-gpm_imerg-resample-xesmfcached-h5netcdf-local.json\nmemray-gpm_imerg-resample-xesmfcached-zarr-icechunk.json\nmemray-gpm_imerg-resample-xesmfcached-zarr-kerchunk.json",
    "crumbs": [
      "Profiling results",
      "Memory and time usage (GPM IMERG)"
    ]
  },
  {
    "objectID": "examples/process-gpm-results.html#show-memory-and-time-for-warp-resampling-dataset",
    "href": "examples/process-gpm-results.html#show-memory-and-time-for-warp-resampling-dataset",
    "title": "Process results for GPM IMERG",
    "section": "Show memory and time for warp resampling dataset",
    "text": "Show memory and time for warp resampling dataset\n\ndf_resample = df[df[\"task\"] == \"resample\"]\ndf_resample.style.background_gradient(cmap=\"YlOrRd\")\n\n\n\n\n\n\n \ndataset\ntask\nmethod\ndriver\nvirtual\npeak memory (GB)\nduration (s)\n\n\n\n\n9\ngpm_imerg\nresample\nxesmfcached\nzarr\nkerchunk\n0.426702\n11.950112\n\n\n7\ngpm_imerg\nresample\nxesmfcached\nh5netcdf\nlocal\n0.427092\n4.640249\n\n\n6\ngpm_imerg\nresample\nxesmfcached\nh5netcdf\n\n0.439300\n11.373503\n\n\n8\ngpm_imerg\nresample\nxesmfcached\nzarr\nicechunk\n0.551259\n12.070593\n\n\n5\ngpm_imerg\nresample\nxesmf\nh5netcdf\nlocal\n1.006814\n39.146913\n\n\n4\ngpm_imerg\nresample\nxesmf\nh5netcdf\n\n1.024223\n43.829477\n\n\n3\ngpm_imerg\nresample\nrioxarray\nh5netcdf\nlocal\n1.141608\n4.208726\n\n\n2\ngpm_imerg\nresample\nrioxarray\nh5netcdf\n\n1.157171\n12.602043\n\n\n1\ngpm_imerg\nresample\nodc\nh5netcdf\nlocal\n1.200322\n4.200772\n\n\n0\ngpm_imerg\nresample\nodc\nh5netcdf\n\n1.218121\n9.698682",
    "crumbs": [
      "Profiling results",
      "Memory and time usage (GPM IMERG)"
    ]
  },
  {
    "objectID": "examples/resample-gdal-netcdf-local.html",
    "href": "examples/resample-gdal-netcdf-local.html",
    "title": "GDAL with NetCDF",
    "section": "",
    "text": "from common import earthaccess_args\nfrom osgeo import gdal\nfrom pyproj.crs import CRS\n\n\ngdal.UseExceptions()\n\n\ndataset = \"gpm_imerg\"\nfilename = earthaccess_args[dataset][\"filename\"]\nvariable = earthaccess_args[dataset][\"variable\"]\n\n\ndef warp_resample():\n    src = f\"NETCDF:earthaccess_data/{filename}:{variable}\"\n    output = \"\"\n    output_format = \"MEM\"\n    dstSRS = \"EPSG:3857\"\n\n    width = height = 256\n    te = [\n        -20037508.342789244,\n        -20037508.342789244,\n        20037508.342789244,\n        20037508.342789244,\n    ]\n    gt = [\n        te[0],\n        (te[2] - te[0]) / width,\n        0,\n        te[3],\n        0,\n        -(te[3] - te[1]) / height,\n    ]\n    output_crs = CRS(dstSRS).to_wkt()\n\n    output_ds = gdal.GetDriverByName(output_format).Create(\n        output, width, height, 1, gdal.GDT_Byte\n    )\n    output_ds.SetProjection(output_crs)\n    output_ds.SetGeoTransform(gt)\n    input_ds = gdal.Open(src)\n    return gdal.Warp(output_ds, input_ds)\n\n\nif __name__ == \"__main__\":\n    warp_resample()",
    "crumbs": [
      "Resampling libraries",
      "GDAL Python API",
      "NetCDF Driver (local)"
    ]
  },
  {
    "objectID": "examples/resample-gdal-vrt-local.html",
    "href": "examples/resample-gdal-vrt-local.html",
    "title": "GDAL with HDF5 and VRT",
    "section": "",
    "text": "from common import earthaccess_args\nfrom osgeo import gdal\nfrom pyproj.crs import CRS\n\n\ngdal.UseExceptions()\n\n\ndataset = \"gpm_imerg\"\nfilename = earthaccess_args[dataset][\"filename\"]\nvariable = earthaccess_args[dataset][\"variable\"]\na_ullr = earthaccess_args[dataset][\"a_ullr\"]\n\n\ndef warp_resample():\n    src = f\"vrt://earthaccess_data/{filename}?a_ullr={a_ullr}&sd_name={variable}\"\n    output = \"\"\n    output_format = \"MEM\"\n    dstSRS = \"EPSG:3857\"\n\n    width = height = 256\n    te = [\n        -20037508.342789244,\n        -20037508.342789244,\n        20037508.342789244,\n        20037508.342789244,\n    ]\n    gt = [\n        te[0],\n        (te[2] - te[0]) / width,\n        0,\n        te[3],\n        0,\n        -(te[3] - te[1]) / height,\n    ]\n    output_crs = CRS(dstSRS).to_wkt()\n\n    output_ds = gdal.GetDriverByName(output_format).Create(\n        output, width, height, 1, gdal.GDT_Byte\n    )\n    output_ds.SetProjection(output_crs)\n    output_ds.SetGeoTransform(gt)\n    input_ds = gdal.Open(src)\n    return gdal.Warp(output_ds, input_ds)\n\n\nif __name__ == \"__main__\":\n    arr = warp_resample()",
    "crumbs": [
      "Resampling libraries",
      "GDAL Python API",
      "NetCDF Driver + vrt (local)"
    ]
  },
  {
    "objectID": "examples/resample-odc-h5netcdf-local.html",
    "href": "examples/resample-odc-h5netcdf-local.html",
    "title": "ODC-geo with H5NetCDF",
    "section": "",
    "text": "import argparse\n\nimport fsspec\nimport xarray as xr\nfrom common import earthaccess_args\nfrom odc.geo.geobox import GeoBox\nfrom odc.geo.xr import xr_reproject\n\n\ndef warp_resample(dataset):\n    args = earthaccess_args[dataset]\n    src = f'earthaccess_data/{args[\"filename\"]}'\n    dstSRS = \"EPSG:3857\"\n    srcSRS = \"EPSG:4326\"\n    width = height = 256\n    te = [\n        -20037508.342789244,\n        -20037508.342789244,\n        20037508.342789244,\n        20037508.342789244,\n    ]\n    fs = fsspec.filesystem(\"file\")\n    with fs.open(src) as f:\n        gbox = GeoBox.from_bbox(te, dstSRS, shape=(height, width))\n        da = xr.open_dataset(f, engine=\"h5netcdf\")[args[\"variable\"]]\n        if dataset == \"gpm_imerg\":\n            da = (\n                da.rename({\"lon\": \"x\", \"lat\": \"y\"})\n                .transpose(\"time\", \"y\", \"x\")\n                .squeeze()\n            )\n        da = da.odc.assign_crs(srcSRS)\n        return xr_reproject(da, gbox)\n\n\nif __name__ == \"__main__\":\n    if \"get_ipython\" in dir():\n        da = warp_resample(\"gpm_imerg\")\n    else:\n        parser = argparse.ArgumentParser(description=\"Set environment for the script.\")\n        parser.add_argument(\n            \"--dataset\",\n            default=\"mursst\",\n            help=\"Dataset to resample.\",\n            choices=[\"gpm_imerg\", \"mursst\"],\n        )\n        user_args = parser.parse_args()\n        da = warp_resample(user_args.dataset)"
  },
  {
    "objectID": "examples/resample-rasterio-netcdf-vsis3.html",
    "href": "examples/resample-rasterio-netcdf-vsis3.html",
    "title": "Rasterio with NetCDF, VSIS3, and earthaccess",
    "section": "",
    "text": "import numpy as np\nimport rasterio\nimport rasterio as rio\nfrom common import earthaccess_args\nfrom rasterio.session import AWSSession\nfrom rasterio.warp import calculate_default_transform, reproject\n\n\ndataset = \"gpm_imerg\"\nfilename = earthaccess_args[dataset][\"filename\"]\nbucket = earthaccess_args[dataset][\"bucket\"]\nfolder = earthaccess_args[dataset][\"folder\"]\nvariable = earthaccess_args[dataset][\"variable\"]\n\n\ndef configure_auth():\n    import boto3\n    import earthaccess\n\n    auth = earthaccess.login()\n    s3_credentials = auth.get_s3_credentials(\"PODAAC\")\n    session = boto3.Session(\n        aws_access_key_id=s3_credentials[\"accessKeyId\"],\n        aws_secret_access_key=s3_credentials[\"secretAccessKey\"],\n        aws_session_token=s3_credentials[\"sessionToken\"],\n        region_name=\"us-west-2\",\n    )\n    rio_env = rio.Env(\n        AWSSession(session),\n    )\n    rio_env.__enter__()\n    return rio_env\n\n\ndef warp_resample():\n    input_uri = f\"{folder}/{filename}\"\n    src = f\"NETCDF:/vsis3/{bucket}/{input_uri}:{variable}\"\n    dstSRS = \"EPSG:3857\"\n    srcSRS = \"EPSG:4326\"\n    width = height = 256\n    with rasterio.open(src) as da:\n        dst_transform, w, h = calculate_default_transform(\n            srcSRS,\n            dstSRS,\n            da.width,\n            da.height,\n            *da.bounds,\n            dst_width=width,\n            dst_height=height,\n        )\n        destination = np.zeros((width, height), np.uint8)\n        return reproject(\n            rasterio.band(da, 1),\n            destination,\n            dst_crs=dstSRS,\n            dst_transform=dst_transform,\n        )\n\n\nif __name__ == \"__main__\":\n    rio_env = configure_auth()\n    warp_resample()\n    rio_env.__exit__()",
    "crumbs": [
      "Resampling libraries",
      "Rasterio",
      "NetCDF Driver + vsis3"
    ]
  },
  {
    "objectID": "examples/resample-rioxarray-h5netcdf-local.html",
    "href": "examples/resample-rioxarray-h5netcdf-local.html",
    "title": "Rioxarray with H5NetCDF",
    "section": "",
    "text": "import argparse\n\nimport fsspec\nimport rasterio as rio  # noqa\nimport xarray as xr\nfrom common import earthaccess_args\nfrom rasterio.warp import calculate_default_transform\n\n\ndef warp_resample(dataset):\n    args = earthaccess_args[dataset]\n    src = f'earthaccess_data/{args[\"filename\"]}'\n    dstSRS = \"EPSG:3857\"\n    srcSRS = \"EPSG:4326\"\n    width = height = 256\n    te = [\n        -20037508.342789244,\n        -20037508.342789244,\n        20037508.342789244,\n        20037508.342789244,\n    ]\n\n    fs = fsspec.filesystem(\"file\")\n    with fs.open(src) as f:\n        da = xr.open_dataset(f, engine=\"h5netcdf\", mask_and_scale=True)[\n            args[\"variable\"]\n        ]\n        if dataset == \"gpm_imerg\":\n            da = da.rename({\"lon\": \"x\", \"lat\": \"y\"}).transpose(\"time\", \"y\", \"x\")\n        da = da.rio.write_crs(srcSRS)\n        da = da.rio.clip_box(\n            *te,\n            crs=dstSRS,\n        )\n        dst_transform, w, h = calculate_default_transform(\n            srcSRS,\n            dstSRS,\n            da.rio.width,\n            da.rio.height,\n            *da.rio.bounds(),\n            dst_width=width,\n            dst_height=height,\n        )\n        return da.rio.reproject(dstSRS, shape=(h, w), transform=dst_transform)\n\n\nif __name__ == \"__main__\":\n    if \"get_ipython\" in dir():\n        da = warp_resample(\"gpm_imerg\")\n    else:\n        parser = argparse.ArgumentParser(description=\"Set environment for the script.\")\n        parser.add_argument(\n            \"--dataset\",\n            default=\"mursst\",\n            help=\"Dataset to resample.\",\n            choices=[\"gpm_imerg\", \"mursst\"],\n        )\n        user_args = parser.parse_args()\n        da = warp_resample(user_args.dataset)"
  },
  {
    "objectID": "examples/resample-xesmf-h5netcdf-.html",
    "href": "examples/resample-xesmf-h5netcdf-.html",
    "title": "XESMF with H5NetCDF and earthaccess",
    "section": "",
    "text": "Requires the upcoming ESMF 8.7 release - https://github.com/pangeo-data/xESMF/issues/380\n\nimport argparse\nimport itertools\n\nimport earthaccess\nimport numpy as np\nimport pyproj\nimport rasterio.transform\nimport xarray as xr\nimport xesmf as xe\nfrom common import earthaccess_args\n\n\ndef make_grid_ds() -&gt; xr.Dataset:\n    \"\"\"\n    Modified from ndpyramid - https://github.com/carbonplan/ndpyramid\n    \"\"\"\n    dstSRS = \"EPSG:3857\"\n    width = height = 256\n    te = [\n        -20037508.342789244,\n        -20037508.342789244,\n        20037508.342789244,\n        20037508.342789244,\n    ]\n\n    transform = rasterio.transform.Affine.translation(\n        te[0], te[3]\n    ) * rasterio.transform.Affine.scale((te[2] * 2) / width, (te[1] * 2) / height)\n\n    p = pyproj.Proj(dstSRS)\n\n    grid_shape = (height, width)\n    bounds_shape = (height + 1, width + 1)\n\n    xs = np.empty(grid_shape)\n    ys = np.empty(grid_shape)\n    lat = np.empty(grid_shape)\n    lon = np.empty(grid_shape)\n    lat_b = np.zeros(bounds_shape)\n    lon_b = np.zeros(bounds_shape)\n\n    # calc grid cell center coordinates\n    ii, jj = np.meshgrid(np.arange(height) + 0.5, np.arange(width) + 0.5)\n    for i, j in itertools.product(range(grid_shape[0]), range(grid_shape[1])):\n        locs = [ii[i, j], jj[i, j]]\n        xs[i, j], ys[i, j] = transform * locs\n        lon[i, j], lat[i, j] = p(xs[i, j], ys[i, j], inverse=True)\n\n    # calc grid cell bounds\n    iib, jjb = np.meshgrid(np.arange(height + 1), np.arange(width + 1))\n    for i, j in itertools.product(range(bounds_shape[0]), range(bounds_shape[1])):\n        locs = [iib[i, j], jjb[i, j]]\n        x, y = transform * locs\n        lon_b[i, j], lat_b[i, j] = p(x, y, inverse=True)\n\n    return xr.Dataset(\n        {\n            \"x\": xr.DataArray(xs[0, :], dims=[\"x\"]),\n            \"y\": xr.DataArray(ys[:, 0], dims=[\"y\"]),\n            \"lat\": xr.DataArray(lat, dims=[\"y\", \"x\"]),\n            \"lon\": xr.DataArray(lon, dims=[\"y\", \"x\"]),\n            \"lat_b\": xr.DataArray(lat_b, dims=[\"y_b\", \"x_b\"]),\n            \"lon_b\": xr.DataArray(lon_b, dims=[\"y_b\", \"x_b\"]),\n        },\n    )\n\n\ndef regrid(dataset):\n    args = earthaccess_args[dataset]\n    input_uri = f'{args[\"folder\"]}/{args[\"filename\"]}'\n    src = f's3://{args[\"bucket\"]}/{input_uri}'\n    target_grid = make_grid_ds()\n    fs = earthaccess.get_s3fs_session(daac=args[\"daac\"])\n    fsspec_caching = {\n        \"cache_type\": \"none\",\n    }\n    with fs.open(src, **fsspec_caching) as f:\n        da = xr.open_dataset(f, engine=\"h5netcdf\", chunks={}, mask_and_scale=True)[\n            args[\"variable\"]\n        ]\n        regridder = xe.Regridder(\n            da,\n            target_grid,\n            \"nearest_s2d\",\n            periodic=True,\n            extrap_method=\"nearest_s2d\",\n            ignore_degenerate=True,\n        )\n        return regridder(da)\n\n\nif __name__ == \"__main__\":\n    if \"get_ipython\" in dir():\n        da = regrid(\"gpm_imerg\")\n    else:\n        parser = argparse.ArgumentParser(description=\"Set environment for the script.\")\n        parser.add_argument(\n            \"--dataset\",\n            default=\"mursst\",\n            help=\"Dataset to resample.\",\n            choices=[\"gpm_imerg\", \"mursst\"],\n        )\n        user_args = parser.parse_args()\n        da = regrid(user_args.dataset)"
  },
  {
    "objectID": "examples/resample-xesmfcached-h5netcdf-.html",
    "href": "examples/resample-xesmfcached-h5netcdf-.html",
    "title": "XESMF with H5NetCDF, earthaccess, and pre-generated weights",
    "section": "",
    "text": "Requires the upcoming ESMF 8.7 release for high-resolution datasets - https://github.com/pangeo-data/xESMF/issues/380\n\nimport argparse\nimport itertools\n\nimport earthaccess\nimport numpy as np\nimport pyproj\nimport rasterio.transform\nimport xarray as xr\nimport xesmf as xe\nfrom common import earthaccess_args\n\n\ndef make_grid_ds() -&gt; xr.Dataset:\n    \"\"\"\n    Modified from ndpyramid - https://github.com/carbonplan/ndpyramid\n    \"\"\"\n    dstSRS = \"EPSG:3857\"\n    width = height = 256\n    te = [\n        -20037508.342789244,\n        -20037508.342789244,\n        20037508.342789244,\n        20037508.342789244,\n    ]\n\n    transform = rasterio.transform.Affine.translation(\n        te[0], te[3]\n    ) * rasterio.transform.Affine.scale((te[2] * 2) / width, (te[1] * 2) / height)\n\n    p = pyproj.Proj(dstSRS)\n\n    grid_shape = (height, width)\n    bounds_shape = (height + 1, width + 1)\n\n    xs = np.empty(grid_shape)\n    ys = np.empty(grid_shape)\n    lat = np.empty(grid_shape)\n    lon = np.empty(grid_shape)\n    lat_b = np.zeros(bounds_shape)\n    lon_b = np.zeros(bounds_shape)\n\n    # calc grid cell center coordinates\n    ii, jj = np.meshgrid(np.arange(height) + 0.5, np.arange(width) + 0.5)\n    for i, j in itertools.product(range(grid_shape[0]), range(grid_shape[1])):\n        locs = [ii[i, j], jj[i, j]]\n        xs[i, j], ys[i, j] = transform * locs\n        lon[i, j], lat[i, j] = p(xs[i, j], ys[i, j], inverse=True)\n\n    # calc grid cell bounds\n    iib, jjb = np.meshgrid(np.arange(height + 1), np.arange(width + 1))\n    for i, j in itertools.product(range(bounds_shape[0]), range(bounds_shape[1])):\n        locs = [iib[i, j], jjb[i, j]]\n        x, y = transform * locs\n        lon_b[i, j], lat_b[i, j] = p(x, y, inverse=True)\n\n    return xr.Dataset(\n        {\n            \"x\": xr.DataArray(xs[0, :], dims=[\"x\"]),\n            \"y\": xr.DataArray(ys[:, 0], dims=[\"y\"]),\n            \"lat\": xr.DataArray(lat, dims=[\"y\", \"x\"]),\n            \"lon\": xr.DataArray(lon, dims=[\"y\", \"x\"]),\n            \"lat_b\": xr.DataArray(lat_b, dims=[\"y_b\", \"x_b\"]),\n            \"lon_b\": xr.DataArray(lon_b, dims=[\"y_b\", \"x_b\"]),\n        },\n    )\n\n\ndef xesmf_weights_to_xarray(regridder) -&gt; xr.Dataset:\n    \"\"\"\n    From ndpyramid - https://github.com/carbonplan/ndpyramid\n    \"\"\"\n    w = regridder.weights.data\n    dim = \"n_s\"\n    ds = xr.Dataset(\n        {\n            \"S\": (dim, w.data),\n            \"col\": (dim, w.coords[1, :] + 1),\n            \"row\": (dim, w.coords[0, :] + 1),\n        }\n    )\n    ds.attrs = {\"n_in\": regridder.n_in, \"n_out\": regridder.n_out}\n    return ds\n\n\ndef _reconstruct_xesmf_weights(ds_w):\n    \"\"\"\n    Reconstruct weights into format that xESMF understands\n\n    From ndpyramid - https://github.com/carbonplan/ndpyramid\n    \"\"\"\n    import sparse\n    import xarray as xr\n\n    col = ds_w[\"col\"].values - 1\n    row = ds_w[\"row\"].values - 1\n    s = ds_w[\"S\"].values\n    n_out, n_in = ds_w.attrs[\"n_out\"], ds_w.attrs[\"n_in\"]\n    crds = np.stack([row, col])\n    return xr.DataArray(\n        sparse.COO(crds, s, (n_out, n_in)), dims=(\"out_dim\", \"in_dim\"), name=\"weights\"\n    )\n\n\ndef reconstruct_weights(weights_fp):\n    return _reconstruct_xesmf_weights(xr.open_zarr(weights_fp))\n\n\ndef get_weights_fp(earthaccess_args):\n    return (\n        \"s3://nasa-veda-scratch/test-weight-caching/\"\n        + earthaccess_args[\"filename\"][:-4]\n        + \"_weights.zarr\"\n    )\n\n\ndef get_target_grid_fp(earthaccess_args):\n    return (\n        \"s3://nasa-veda-scratch/test-weight-caching/\"\n        + earthaccess_args[\"filename\"][:-4]\n        + \"_target.zarr\"\n    )\n\n\ndef generate_weights(dataset):\n    args = earthaccess_args[dataset]\n    weights_fp = get_weights_fp(args)\n    target_grid_fp = get_target_grid_fp(args)\n    input_uri = f'{args[\"folder\"]}/{args[\"filename\"]}'\n    src = f's3://{args[\"bucket\"]}/{input_uri}'\n    target_grid = make_grid_ds()\n    target_grid.to_zarr(target_grid_fp, mode=\"w\")\n    fs = earthaccess.get_s3fs_session(daac=args[\"daac\"])\n    fsspec_caching = {\n        \"cache_type\": \"none\",\n    }\n    with fs.open(src, **fsspec_caching) as f:\n        da = xr.open_dataset(f, engine=\"h5netcdf\", chunks={}, mask_and_scale=True)[\n            args[\"variable\"]\n        ]\n        regridder = xe.Regridder(\n            da,\n            target_grid,\n            \"nearest_s2d\",\n            periodic=True,\n            extrap_method=\"nearest_s2d\",\n            ignore_degenerate=True,\n        )\n        weights = xesmf_weights_to_xarray(regridder)\n        weights.to_zarr(weights_fp, mode=\"w\")\n\n\ndef regrid(dataset):\n    args = earthaccess_args[dataset]\n    weights_fp = get_weights_fp(args)\n    target_grid_fp = get_target_grid_fp(args)\n    weights = reconstruct_weights(weights_fp)\n    grid = xr.open_zarr(target_grid_fp)\n    input_uri = f'{args[\"folder\"]}/{args[\"filename\"]}'\n    src = f's3://{args[\"bucket\"]}/{input_uri}'\n    fs = earthaccess.get_s3fs_session(daac=args[\"daac\"])\n    fsspec_caching = {\n        \"cache_type\": \"none\",\n    }\n    with fs.open(src, **fsspec_caching) as f:\n        da = xr.open_dataset(f, engine=\"h5netcdf\", mask_and_scale=True)[\n            args[\"variable\"]\n        ]\n        regridder = xe.Regridder(\n            da,\n            grid,\n            \"nearest_s2d\",\n            periodic=True,\n            extrap_method=\"nearest_s2d\",\n            ignore_degenerate=True,\n            reuse_weights=True,\n            weights=weights,\n        )\n        return regridder(da)\n\n\nif __name__ == \"__main__\":\n    if \"get_ipython\" in dir():\n        da = regrid(\"gpm_imerg\")\n    else:\n        parser = argparse.ArgumentParser(description=\"Set environment for the script.\")\n        parser.add_argument(\n            \"--dataset\",\n            default=\"gpm_imerg\",\n            help=\"Dataset to resample.\",\n            choices=[\"gpm_imerg\", \"mursst\"],\n        )\n        parser.add_argument(\n            \"--gen-weights\",\n            default=False,\n            help=\"Generate weights\",\n            action=argparse.BooleanOptionalAction,\n        )\n        user_args = parser.parse_args()\n        if user_args.gen_weights:\n            generate_weights(user_args.dataset)\n        da = regrid(user_args.dataset)"
  },
  {
    "objectID": "examples/resample-xesmfcached-zarr-icechunk.html",
    "href": "examples/resample-xesmfcached-zarr-icechunk.html",
    "title": "XESMF with Zarr, icechunk, earthaccess, and pre-generated weights",
    "section": "",
    "text": "Requires the upcoming ESMF 8.7 release for high-resolution datasets - https://github.com/pangeo-data/xESMF/issues/380\n\nimport argparse\nimport itertools\n\nimport earthaccess\nimport numpy as np\nimport pyproj\nimport rasterio.transform\nimport xarray as xr\nimport xesmf as xe\nfrom common import earthaccess_args\nfrom icechunk import IcechunkStore, StorageConfig\n\n\ndef make_grid_ds() -&gt; xr.Dataset:\n    \"\"\"\n    Modified from ndpyramid - https://github.com/carbonplan/ndpyramid\n    \"\"\"\n    dstSRS = \"EPSG:3857\"\n    width = height = 256\n    te = [\n        -20037508.342789244,\n        -20037508.342789244,\n        20037508.342789244,\n        20037508.342789244,\n    ]\n\n    transform = rasterio.transform.Affine.translation(\n        te[0], te[3]\n    ) * rasterio.transform.Affine.scale((te[2] * 2) / width, (te[1] * 2) / height)\n\n    p = pyproj.Proj(dstSRS)\n\n    grid_shape = (height, width)\n    bounds_shape = (height + 1, width + 1)\n\n    xs = np.empty(grid_shape)\n    ys = np.empty(grid_shape)\n    lat = np.empty(grid_shape)\n    lon = np.empty(grid_shape)\n    lat_b = np.zeros(bounds_shape)\n    lon_b = np.zeros(bounds_shape)\n\n    # calc grid cell center coordinates\n    ii, jj = np.meshgrid(np.arange(height) + 0.5, np.arange(width) + 0.5)\n    for i, j in itertools.product(range(grid_shape[0]), range(grid_shape[1])):\n        locs = [ii[i, j], jj[i, j]]\n        xs[i, j], ys[i, j] = transform * locs\n        lon[i, j], lat[i, j] = p(xs[i, j], ys[i, j], inverse=True)\n\n    # calc grid cell bounds\n    iib, jjb = np.meshgrid(np.arange(height + 1), np.arange(width + 1))\n    for i, j in itertools.product(range(bounds_shape[0]), range(bounds_shape[1])):\n        locs = [iib[i, j], jjb[i, j]]\n        x, y = transform * locs\n        lon_b[i, j], lat_b[i, j] = p(x, y, inverse=True)\n\n    return xr.Dataset(\n        {\n            \"x\": xr.DataArray(xs[0, :], dims=[\"x\"]),\n            \"y\": xr.DataArray(ys[:, 0], dims=[\"y\"]),\n            \"lat\": xr.DataArray(lat, dims=[\"y\", \"x\"]),\n            \"lon\": xr.DataArray(lon, dims=[\"y\", \"x\"]),\n            \"lat_b\": xr.DataArray(lat_b, dims=[\"y_b\", \"x_b\"]),\n            \"lon_b\": xr.DataArray(lon_b, dims=[\"y_b\", \"x_b\"]),\n        },\n    )\n\n\ndef xesmf_weights_to_xarray(regridder) -&gt; xr.Dataset:\n    \"\"\"\n    From ndpyramid - https://github.com/carbonplan/ndpyramid\n    \"\"\"\n    w = regridder.weights.data\n    dim = \"n_s\"\n    ds = xr.Dataset(\n        {\n            \"S\": (dim, w.data),\n            \"col\": (dim, w.coords[1, :] + 1),\n            \"row\": (dim, w.coords[0, :] + 1),\n        }\n    )\n    ds.attrs = {\"n_in\": regridder.n_in, \"n_out\": regridder.n_out}\n    return ds\n\n\ndef _reconstruct_xesmf_weights(ds_w):\n    \"\"\"\n    Reconstruct weights into format that xESMF understands\n\n    From ndpyramid - https://github.com/carbonplan/ndpyramid\n    \"\"\"\n    import sparse\n    import xarray as xr\n\n    col = ds_w[\"col\"].values - 1\n    row = ds_w[\"row\"].values - 1\n    s = ds_w[\"S\"].values\n    n_out, n_in = ds_w.attrs[\"n_out\"], ds_w.attrs[\"n_in\"]\n    crds = np.stack([row, col])\n    return xr.DataArray(\n        sparse.COO(crds, s, (n_out, n_in)), dims=(\"out_dim\", \"in_dim\"), name=\"weights\"\n    )\n\n\ndef generate_weights(dataset):\n    args = earthaccess_args[dataset]\n    weights_storage = StorageConfig.s3_from_env(\n        bucket=\"nasa-veda-scratch\",\n        prefix=\"icechunk/test-weight-caching/weights\",\n        region=\"us-west-2\",\n    )\n    target_storage = StorageConfig.s3_from_env(\n        bucket=\"nasa-veda-scratch\",\n        prefix=\"icechunk/test-weight-caching/target\",\n        region=\"us-west-2\",\n    )\n\n    weights_store = IcechunkStore.open_or_create(storage=weights_storage, mode=\"w\")\n    target_store = IcechunkStore.open_or_create(storage=target_storage, mode=\"w\")\n\n    input_uri = f'{args[\"folder\"]}/{args[\"filename\"]}'\n    src = f's3://{args[\"bucket\"]}/{input_uri}'\n    target_grid = make_grid_ds()\n    target_grid.to_zarr(target_store, zarr_format=3, consolidated=False)\n    fs = earthaccess.get_s3_filesystem(daac=args[\"daac\"])\n    fsspec_caching = {\n        \"cache_type\": \"none\",\n    }\n    with fs.open(src, **fsspec_caching) as f:\n        da = xr.open_dataset(f, engine=\"h5netcdf\", chunks={}, mask_and_scale=True)[\n            args[\"variable\"]\n        ]\n        regridder = xe.Regridder(\n            da,\n            target_grid,\n            \"nearest_s2d\",\n            periodic=True,\n            extrap_method=\"nearest_s2d\",\n            ignore_degenerate=True,\n        )\n        weights = xesmf_weights_to_xarray(regridder)\n        weights.to_zarr(weights_store, zarr_format=3, consolidated=False)\n    target_store.commit(\"Generate target grid\")\n    weights_store.commit(\"Generate weights\")\n\n\ndef regrid(dataset):\n    args = earthaccess_args[dataset]\n    weights_storage = StorageConfig.s3_from_env(\n        bucket=\"nasa-veda-scratch\",\n        prefix=\"icechunk/test-weight-caching/weights\",\n        region=\"us-west-2\",\n    )\n    target_storage = StorageConfig.s3_from_env(\n        bucket=\"nasa-veda-scratch\",\n        prefix=\"icechunk/test-weight-caching/target\",\n        region=\"us-west-2\",\n    )\n    weights_store = IcechunkStore.open_existing(storage=weights_storage, mode=\"r\")\n    target_store = IcechunkStore.open_existing(storage=target_storage, mode=\"r\")\n    storage = StorageConfig.s3_from_env(\n        bucket=\"nasa-veda-scratch\",\n        prefix=\"icechunk/test-weight-caching/reference\",\n        region=\"us-west-2\",\n    )\n    store = IcechunkStore.open_existing(storage=storage, mode=\"r\")\n    weights = _reconstruct_xesmf_weights(\n        xr.open_zarr(weights_store, zarr_version=3, consolidated=False)\n    )\n    grid = xr.open_zarr(target_store, zarr_version=3, consolidated=False)\n    da = xr.open_zarr(store, zarr_version=3, consolidated=False)[args[\"variable\"]]\n    regridder = xe.Regridder(\n        da,\n        grid,\n        \"nearest_s2d\",\n        periodic=True,\n        extrap_method=\"nearest_s2d\",\n        ignore_degenerate=True,\n        reuse_weights=True,\n        weights=weights,\n    )\n    return regridder(da)\n\n\nif __name__ == \"__main__\":\n    da = regrid(\"gpm_imerg\")\n    if \"get_ipython\" in dir():\n        generate_weights(\"gpm_imerg\")\n        da = regrid(\"gpm_imerg\")\n    else:\n        parser = argparse.ArgumentParser(description=\"Set environment for the script.\")\n        parser.add_argument(\n            \"--dataset\",\n            default=\"gpm_imerg\",\n            help=\"Dataset to resample.\",\n            choices=[\"gpm_imerg\", \"mursst\"],\n        )\n        parser.add_argument(\n            \"--gen-weights\",\n            default=False,\n            help=\"Generate weights\",\n            action=argparse.BooleanOptionalAction,\n        )\n        user_args = parser.parse_args()\n        if user_args.gen_weights:\n            generate_weights(user_args.dataset)\n        da = regrid(user_args.dataset)"
  },
  {
    "objectID": "examples/run-memray.html",
    "href": "examples/run-memray.html",
    "title": "Geospatial reprojection in Python (2024)",
    "section": "",
    "text": "import subprocess\nfrom datetime import datetime\nfrom pathlib import Path\n\nimport fsspec\nfrom utils import sync_notebook\n\n\nfs = fsspec.filesystem(\"file\")\ncurrent_date = datetime.today().strftime(\"%Y-%m-%d\")\noutput_folder = f\"results/{current_date}/\"\nfiles = fs.glob(f\"{output_folder}memray-*.json\")\nfs.rm(files)\nfs.mkdirs(output_folder, exist_ok=True)\n\n\ndataset = \"gpm_imerg\"\n\n\ndef run_memray(file: str):\n    output_file = output_folder + \"memray-\" + dataset + \"-\" + Path(file).stem + \".bin\"\n    summary_file = output_folder + \"memray-\" + dataset + \"-\" + Path(file).stem + \".json\"\n    command = [\n        \"memray\",\n        \"run\",\n        \"--force\",\n        \"--output\",\n        output_file,\n        file,\n        \"--dataset\",\n        dataset,\n    ]\n    subprocess.run(command)\n    summary_command = [\n        \"memray\",\n        \"stats\",\n        \"--force\",\n        \"--json\",\n        \"--output\",\n        summary_file,\n        output_file,\n    ]\n    subprocess.run(summary_command)\n\n\ninput_methods = [\"resample-rioxarray-h5netcdf\", \"resample-odc\", \"resample-xesmf\"]\n\n\nnotebooks = []\nfor fp in input_methods:\n    notebooks.extend(fs.glob(f\"{fp}*.ipynb\"))\n\n\nfor file in notebooks:\n    sync_notebook(file)\n\n\nmodules = []\nfor fp in input_methods:\n    modules.extend(fs.glob(f\"{fp}*.py\"))\nfor file in modules:\n    run_memray(file)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Warp resampling",
    "section": "",
    "text": "This a work-in-progress guidebook on existing warp resampling / reprojection methods in Python, along with some memory and statistical wall-time profiling results.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Warp resampling",
    "section": "",
    "text": "This a work-in-progress guidebook on existing warp resampling / reprojection methods in Python, along with some memory and statistical wall-time profiling results.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#caveat",
    "href": "index.html#caveat",
    "title": "Warp resampling",
    "section": "Caveat",
    "text": "Caveat\nThis is a WIP guidebook. We are presenting early on in the development to guide discussions and future work. The output from different resampling methods has not yet been verified, important parameters (e.g., target no_data values) have not been set, and not all methods have been implemented. We encourage people to contribute by building on the notebooks in the examples directory or participating in discussions on this repo or on the Pangeo discourse.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#memory-and-time-profiling",
    "href": "index.html#memory-and-time-profiling",
    "title": "Warp resampling",
    "section": "Memory and time profiling",
    "text": "Memory and time profiling\nResampling and reprojection (i.e., warp resampling) are essential steps for generating raster tiles for browser based visualization. Further, warp resampling is often one of the most time consuming and memory intensive portions of the tile generation process. The importance and complexity of this step motivates an exploration of different warp resampling options.\n\nGoals\nCompare memory and time performance for generating a zoom level 0 256 x 256 raster from one timestep and variable of the MUR SST dataset using the following approaches:\n\nosgeo.warp\nrasterio.warp.reproject\nrioxarray.reproject\npyresample.resample_blocks\nxesmf.Regridder\ngeoutils.Raster.reproject\nraster_tools.warp.reproject\nodc.geo.xr.xr_reproject\nxcube.resampling\ngeowombat.config.update\n\nOut-of-scope:\n\nxarray-regrid - only regrids within the same rectilinear coordinate system\nweatherbench2/regridding - only seems to regrid within the same rectilinear coordinate system\ndinosaur - only seems to regrid within the same rectilinear coordinate system\npygmt.grdproject - web mercator not amongst supported projections\nverde - not used for raster -&gt; raster resampling (only points -&gt; raster)\n\nThese methods will be run on the full resolution dataset. Nearest neighbor interpolation will be used for the first comparison. For simplicity, the amount of time necessary to generate a resampled array and the maximum amount of heap memory allocated will be measured.\n\n\nPlanned extensions\n\nCompare to results when using a 2x and 4x downsampled versions to better understand the time and memory complexity\nCompare to results when using a virtual dataset (e.g., VRT, Kerchunk reference file).\nCompare results when reading from a dataset stored locally versus in cloud object storage.\nCompare to results when using a cloud-optimized dataset (Zarr).\n\n\n\nPossible extensions\n\nCompare other resampling methods (e.g., bilinear, conservative).\nCompare with methods that don’t rely on existing packages (e.g., Conservative regridding with Xarray, GeoPandas, and Sparse and KDTree wrappers).\n\n\n\nEnvironment Setup\nThe notebooks can be run on a JupyterHub environment using the docker image quay.io/developmentseed/warp-resample-profiling:latest, which is created using repo2docker using the Dockerfile contained within the binder directory.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "Warp resampling",
    "section": "References",
    "text": "References\n\nWhat’s Next - Software - Regridding\nLazy regridding discussion\n\n\nAcknowledgements\nThis work was made possible through support from NASA IMPACT. Numerous people have guided development, especially Aimee Barciauskas (@abarciauskas-bgse), Justus Magin (@keewis), and Michael Sumner (@mdsumner). The resources page contains references for source information. Quarto configuration based on Cloud Native Geospatial Formats Guide and the Tile Benchmarking(https://developmentseed.org/tile-benchmarking/). All mistakes my own.",
    "crumbs": [
      "Welcome"
    ]
  }
]